\documentclass[fontsize=12pt]{scrartcl}

\title{Lecture Notes\\
PHY 512\\
Quantum Mechanics II}
\author{Alec Wills}
\date{}

\usepackage{amsmath}
\usepackage{fullpage}
\newcommand*{\diff}{\mathop{}\!\mathrm{d}}
\newcommand*{\Diff[1]}{\mathop{}\!\mathrm{d^#1}}
\usepackage{amssymb}
\usepackage{titling}
\usepackage{enumerate}
%make quotation marks work correctly
\usepackage[english]{babel}
\usepackage[autostyle, english = american]{csquotes}
\MakeOuterQuote{"}
%So I can use negative forms of operations
\usepackage{cancel}
%So I can set the multiplication properties to list correctly. Requires stickin label= in front of option, and e.g. \alph or \arabic to specify the characters
\usepackage{enumitem}
%Define new operator for the Image of a function.
\DeclareMathOperator{\Ima}{Im}
\DeclareMathOperator{\trace}{trace}
\DeclareMathOperator{\signa}{sign}

%Use package breqn to split automatically
\usepackage{breqn}
%For nice integral stuff
\usepackage{esint}
%Define command to make boldface vectors as opposed to the arrow
\newcommand{\bv}[1]{\mathrm{\textbf{#1}}}

\newcommand{\bb}[1]{\mathbb{#1}}

%Define roman numeral command for math mode$
\newcommand{\RN}[1]{\textup{\uppercase\expandafter{\romannumeral#1}}}

%package for boxing lemmas and things
\usepackage{mdframed}

\newcommand{\limv}[2]{\lim\limits_{#1\rightarrow #2}}

\newcommand{\llangle}{\langle\langle}
\newcommand{\rrangle}{\rangle\rangle}

\newcommand{\x}{\bv{x}}
\newcommand{\xdot}{\dot{\bv{x}}}
\newcommand{\lag}{\mathcal{L}}
\newcommand{\pv}{\bv{p}}
\newcommand{\ham}{\mathcal{H}}
\newcommand{\Id}{\bb{I}}

\DeclareMathOperator{\inte}{int}
\DeclareMathOperator{\supp}{supp}

\usepackage{color}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    linktoc=all,
    filecolor=magenta,      
    urlcolor=cyan,
    bookmarks=true,
}

\urlstyle{same}
\setcounter{tocdepth}{4}

\newcommand{\ptl}{\partial}
\newcommand{\la}{\langle}
\newcommand{\ra}{\rangle}
\newcommand{\pos}{\hat{x}}
\newcommand{\posv}{\vec{\hat{x}}}
\newcommand{\mom}{\hat{p}}
\newcommand{\momv}{\vec{\hat{p}}}
\newcommand{\Ham}{\hat{\mathcal{H}}}

%Build sumint
\usepackage{graphicx}
\DeclareMathOperator*{\SumInt}{%
\mathchoice%
  {\ooalign{$\displaystyle\sum$\cr\hidewidth$\displaystyle\int$\hidewidth\cr}}
  {\ooalign{\raisebox{.14\height}{\scalebox{.7}{$\textstyle\sum$}}\cr\hidewidth$\textstyle\int$\hidewidth\cr}}
  {\ooalign{\raisebox{.2\height}{\scalebox{.6}{$\scriptstyle\sum$}}\cr$\scriptstyle\int$\cr}}
  {\ooalign{\raisebox{.2\height}{\scalebox{.6}{$\scriptstyle\sum$}}\cr$\scriptstyle\int$\cr}}
}

\newcommand{\hop}{\hat{a}}
\newcommand{\hopd}{\hat{a}^\dagger}
\newcommand{\Nop}{\hat{N}}

\newcommand{\lam}{\lambda}



\begin{document}
\maketitle

\tableofcontents{}

\section{Day 1: 1/23}

\subsection{Continuous Symmetries}

We begin by reviewing the end of last semester's material: continuous symmetries. The most simple form of a continuous symmetry in quantum mechanics is that of translation. If the space is uniform, the dynamics are invariant under translation, we have a conservation law as we will see later.

We note that we require any symmetry operator of a state ket to preserve its probability, which immediately implies that a symmetry operator $U$ has the property that $UU^\dagger=\Id$, or that $U$ is a unitary operator.

In one-dimension, we recall that the defining property of the translation operator is $T_a|x\ra = |x+a\ra$. This form is self-evident in the position Hilbert space, but what of a generic function ket $T_a|f\ra$? To see the form of the translation operator here, we project $\la x+a|f\ra=f(x+a)=T_a^\dagger f(x)$. But $f(x+a)$ can be Taylor expanded to find that $$T_a^\dagger f(x)=e^{aD_x}f(x)\implies T_a^\dagger=e^{ia\mom/\hbar},  \ \ \ \mom - \frac{\hbar}{i}\frac{d}{dx}.$$ We note that the unitarity requirement on $T_a$ is only satisfied if $\mom$ is hermitian, as a term $\propto \Id + \mom^\dagger-\mom$ appears in $T_aT_a^\dagger$. This is the momentum operator in the $x$-representation, and we see it has units of momentum. So \begin{mdframed}
$$T_a=e^{\frac{-ia}{\hbar}\mom}.$$
\end{mdframed} The translations embodied by the unitary $T_a$ are generated by a hermitian operator $\mom$. The symmetry in one space is embodied by a generating conserved charge in its conjugate space. We call this specific $T_a$ a member of the group $U(1)$, the group of unitary transformations generated by one element. It has identity $T_0$, inverses and associativity. The group generator is obtained by the infinitesimal form $T_\epsilon\approx\Id-\frac{ia}{\hbar}\mom$, so we see $\mom$ is the Lie generator of $U(1)$. The group is inherently abelian because it is formed by one element.

Now, if $\Ham$ is invariant under translation, then it commutes with $T_a$ and therefore with the generating element $\mom$, so $[\Ham,\mom]=0$. But by the Heisenberg picture, $$i\hbar \frac{d}{dt}\mom=[\mom,\Ham]=0$$ so we see that momentum is conserved, and thus the expectation value of a measurement does not change in time. We note that in $D$-dimensions, $[p_i,p_j]=0$.

Classical rotations and encoded by matrices. IF the space is isotropic, then the rotations are the right way to think about symmetry in that space. (However, crystalline structures are not totally isotropic, so continuous symmetries do not apply to them.)

In normal space, we have $v_i'=R_{ij}(\theta)v_j$. The matrix relates the components of the old and new vectors, and the choice of the table depends on the basis we work in. There are typically two canonical bases: the lab frame (in which space is fixed, and Cartesian coordinates are used) or the body frame, in which the rotating object seems stationary. In the lab frame, we have $$R_z(\theta)=\left(\begin{matrix}
\cos\theta & -\sin\theta & 0\\
\sin\theta & \cos\theta & 0\\
0 & 0 & 1
\end{matrix}\right) \to R_z(\epsilon)=\Id+\left(\begin{matrix}
0 & - \epsilon & 0\\ \epsilon & 0 & 0\\ 0&0&0
\end{matrix}\right)=\Id+\epsilon G_z.$$ So we have one Lie generator $G_z$. We note that rotations preserve the norm, so that $R^T=R^{-1}$, which is the signature group of $O(D=3)$ here (the orthogonal group). The right-handedness of our rotations implies that the determinants of all rotation matrices are equal to $+1$, which is the requirement of $SO(3)$. All the directional $G_i$s are the Lie generators of $O(3)$. So similarly, we have $$G_x=\left(\begin{matrix}
0 & 0 & 0\\ 0 & 0 & -1\\ 0&1&0
\end{matrix}\right), \ \ \ G_y=\left(\begin{matrix}
0 & 0 & 1\\ 0 & 0 & 0\\ -1&0&0
\end{matrix}\right). $$ Now these generators no longer commute, and we can find that $$[G_i, G_j]=\epsilon_{ijk}G_k,$$ which is the defining Lie algebra of the $SO(3)$ generators.

We now move to the Hilbert space for quantum mechanics considerations. We no longer rotate vectors in 3-space, but abstract kets in a space of larger dimension. We assume the transformations lifted from 3-space to the Hilbert space are linear, and that they are norm preserving again to conserve probability: $|\alpha\ra_R=D(R)|\alpha\ra$. Norm invariance implies again that $D^\dagger=D^{-1}$ so that $D$ is a unitary transformation.

Take, for instance $D(R_z(\theta))$. How does $R_z(\theta)$ acting on normal space lift itself to the Hilbert space? We consider the infinitesimal form: $$D(R_z(\epsilon)\approx \Id +\epsilon G_z)\approx D(\Id)+\epsilon D'(\Id) +\dots,$$ where we've expanded $D$ in its continuous parameter $\epsilon$. Now $D(\Id)=\Id_H$ by definition, although the new identity is the abstract identity in the larger space. Because $D$ is unitary, we therefore can define (infinitesimally) $$D(\epsilon)\approx \Id_H-\frac{i\epsilon}{\hbar}\hat{J}_z.$$ This will again imply that $\hat{J}_z$ is hermitian, with units of angular momentum. So if the Hamiltonian is rotationally symmetric, it will commute with the rotation operator and thus the Lie generators $J_i$: $$i\hbar \frac{d}{dt}J_i=[J_i,\Ham]=0,$$ so angular momentum is conserved in rotationally symmetric systems.

But which unitary group are these state rotations? We want to find the Lie algebra that will tell us what is generated. We know how to express $D$ in terms of the lifted rotation operators $R$, and we know that $R_x(\epsilon)R_y(\epsilon)\approxeq R_y(\epsilon)R_x(\epsilon)R_z(\epsilon^2),$ where the $\epsilon^2$ term comes in from the commutation relations. We lift it to the Hilbert space, expressing $D(R(\epsilon))$ in terms of $\epsilon$ powers of $J_i$, and up to $\epsilon^2$ we find that $$[J_i,J_j]=i\hbar \epsilon_{ijk} J_k.$$ This is the defining Lie algebra of $SU(2)$ We now want to find out how the operator looks in a specific basis.

It is stated without proof that all representations of $SU(2)$ are finite dimensional, and we now concern ourselves with finding the lowest-dimensional representation. (It ends up being 2-dimensional, representing spin-1/2).

Now we know that $\vec{J}=\vec{L}+\vec{S}$, where $\vec{L}$ is the orbital angular momentum and $\vec{S}$ is the spin. The lowest dimensional representation has no orbital term at all, so we are left with $J_i\to S_i$, where $S_i$ will be a two-by-two matrix.

In the lowest dimensional representation, then, $$D_{1/2}(R_z(\theta))=e^{-i\theta S_z/\hbar}=e^{\frac{-i\theta}{\hbar}\frac{\hbar}{2}\sigma_z}=e^{i\theta\sigma_z/2}=\left(\begin{matrix}
e^{-i\theta/2}&0\\0&e^{i\theta/2}
\end{matrix}\right).$$ However, the most general rotation along a unit vector $\hat{n}$ at an angle $\beta$ w.r.t. the $z$-axis and an angle $\alpha$ w.r.t. the $x$-axis by an angle $\phi$ is given by $$R_{\hat{n}}(\phi)=e^{\phi\hat{n}\cdot\vec{G}}.$$ When lifting to $D_{1/2}$, it instead reads \begin{mdframed} $$ D_{1/2}(R_{\hat{n}}(\phi))=e^{\frac{i\phi}{\hbar}\hat{n}\cdot\vec{S}}.$$\end{mdframed}

As an example, suppose we know the ket's spin is $|+\ra_z=\left(\begin{smallmatrix}
1\\0
\end{smallmatrix}\right)=\chi_z$. What would be $\chi_{\hat{n}}$? We know that it will be diagonal in its own basis, such that $S_{\hat{n}}\chi_{\hat{n}}=+\frac{\hbar}{2}\chi_{\hat{n}},$ but we would need to diagonalize the left hand side since $S_{\hat{n}}(S_x, S_y, S_z)$ will not be diagonal in the original basis. But we could also compute the value by just rotating coordinate axes as we would classically: begin with your state aligned as $|+\ra_z$, then rotate about the $y$-axis by some angle $\beta$, then again about the $z$-axis by an angle $\alpha$, so that the original state lies along the vector $\hat{n}$. In the Hilbert space, this maneuver is done by $$\chi_{\hat{n}}=D(R_z(\alpha))D(R_y(\beta))\chi_z=e^{\frac{-i\alpha}{\hbar}\frac{\hbar}{2}\sigma_z}e^{\frac{-i\beta}{\hbar}\frac{\hbar}{2}\sigma_y}\chi_z=\left(\begin{matrix}
e^{-i\alpha/2}&0\\0&e^{i\alpha/2}
\end{matrix}\right)\left(\begin{matrix}
\cos\frac{\beta}{2} & -\sin\frac{\beta}{2}\\\sin\frac{\beta}{2}&\cos\frac{\beta}{2}
\end{matrix}\right)\left(\begin{matrix}
1\\0
\end{matrix}\right)$$, which when simplified down to the final result yields $$\left(\begin{matrix}
\cos\frac{\beta}{2} e^{i\alpha/2}\\-\sin\frac{\beta}{2}e^{i\alpha/2}
\end{matrix}\right) \leftrightarrow S_{\hat{n}}\chi_{\hat{n}}=+\frac{\hbar}{2}\chi_{\hat{n}}.$$


\section{Day 2: 1/25}

\subsection{Continuous Symmetries}

Once you identify a symmetry, you can use it to restrain the forms of a wave function describing the state. Most symmetries form groups (if continuous), but some anti-unitary symmetries do not (some examples are discrete symmetries).

The key elements of a symmetry are the Lie generators of the group, with a certain algebraic signature (in the case of quantum mechanical rotations, we have the signature of $SU(2)$.) 

\subsection{Spin Precession}

We begin with a spin state $|+\ra_y$ and a magnetic field $\bv{B}=B\hat{z}$. We recall the Hamiltonian $\Ham=-\vec{\mu}\cdot\bv{B}$, where the magnetic moment can be given by $$\mu = \frac{IA}{c}=\frac{e}{T}\frac{\pi R^2}{c}=\frac{e\omega}{2c} R^2 = \frac{evR}{2c}=\frac{e}{2mc}L,$$ where $L$ is the angular momentum, $I$ is the current around a loop of area $A$. If we lift this to a quantum mechanical operator, the Dirac equation yields $$\hat{\mu}=g_e \frac{e}{2mc}\vec{S}=\frac{e}{mc}\vec{S}=\frac{e\hbar}{2mc}\vec{\sigma}.$$ This finally gives a Hamiltonian of the form $$\Ham = -\frac{\hbar}{2} \frac{eB}{mc}\sigma_z = -\frac{\hbar\omega_c}{2}\sigma_z,$$ where $\omega_c$ is the cyclotron frequency. This tells us we have a time evolution operator of the form $$U(t)=e^{-it\Ham/\hbar}=e^{i\omega_c t\sigma_z/2}.$$ But this time evolution operator looks similar to a rotation $D(R_{\hat{n}}(\theta))=e^{-i\theta \vec{S}\cdot\hat{n}/\hbar}$, where we identify $\theta=-\omega_ct$ and $\sigma_n\to \sigma_z$ by virtue of the given field. This is a departure from classical considerations, where the magnetic moment would only align with the field.

For the precession, we'll focus on the observable instead of the state like we did last semester. We know in the Heisenberg picture that $$S(t)=U^\dagger(t)S(0)U(t),$$ and since $U(t)$ here only uses $\sigma_z$, it can be simplified into a diagonal matrix. When considering $S_z$, all matrices are diagonal, and we can commute for $S_z(t)=U^\dagger(t)S_z(0)U(t)=S_z(0)$. The non-diagonal $S_x, S_y$ however do now remain the same (thus the precession). At the end of all the matrix multiplication, one finds $$\left(\begin{matrix}
S_x(t)\\S_y(t)\\S_z(t)
\end{matrix}\right) = \left(\begin{matrix}
\cos(\omega_c t) & \sin(\omega_c t) & 0 \\
-\sin(\omega_c t) & \cos(\omega_c t) & 0\\
0&0&1
\end{matrix}\right)\left(\begin{matrix}
S_x(0)\\S_y(0)\\S_z(0)
\end{matrix}\right),$$ or, more succinctly, $\vec{S}(t)=R_z(-\omega_c t)\vec{S}(0)$. So we see that the symmetry here, acting on the observables, takes the form of a "real" rotation in 3-space about the axis of precession.

\subsection{Euler Representation}
In the body-fixed frame (typically associated as a frame attached to a rotating top, we begin by a rotation of $\alpha$ around the $z$-axis, generating new axes $x'$ and $y'$. We then rotate around $y'$ by $\beta$ to generate a new $z'$ axis, and we rotate around the $z'$ axis by $\gamma$ to align with the axis of rotation. The angle $\alpha,\beta,\gamma$ are the Euler angles, and the canonical rotation we do to form the new coordinates is $$R(\alpha\beta\gamma)=R_{z'}(\gamma)R_{y'}(\beta)R_z{\alpha}.$$ But the rotations here aren't all with respect to the fixed original frame, so we must express them differently. We note that we can express $R_{y'}(\beta)$ as a change of basis by rotation about the $z$-axis by $\alpha$, so that $$R_{y'}(\beta)=R_z(\alpha)R_y(\beta)R_z^{-1}(\alpha).$$ Similarly, for $R_{z'}(\gamma)$, we can express it as a change of basis by rotation around the $y'$ axis: $$R_{z'}(\gamma)=R_{y'}(\beta)R_z(\gamma)R_{y'}^{-1}(\beta).$$ So expanding as everything, and noting that rotations along the same axis commute, we can expand and cancel terms to find $$R(\alpha\beta\gamma)=R_z(\alpha)R_y(\beta)R_z(\gamma).$$ Now, we wish to lift this to the quantum mechanical regime, as a unitary transformation $D(R(\alpha\beta\gamma))$. But the representation distributes itself, so in the body fixed frame the transformation completely factorizes: $$D(\alpha\beta\gamma)=e^{-i\alpha J_z/\hbar}e^{-i\beta J_y/\hbar}e^{-i\gamma J_z/\hbar}.$$ For example, in the $D_{1/2}$ representation, we would have \begin{align*}D_{1/2}(\alpha\beta\gamma)&=\left(\begin{matrix}
e^{-i\alpha/2}&0\\0&e^{i\alpha/2}
\end{matrix}\right) e^{-i\beta \sigma_y/2} \left(\begin{matrix}
e^{-i\gamma/2}&0\\0&e^{i\gamma/2}
\end{matrix}\right)\\&=\left(\begin{matrix}
e^{-i\alpha/2}&0\\0&e^{i\alpha/2}
\end{matrix}\right) \left(\cos(\beta/2)\Id - i\sin(\beta/2)\sigma_y\right)  \left(\begin{matrix}
e^{-i\gamma/2}&0\\0&e^{i\gamma/2}
\end{matrix}\right).\end{align*}

\subsection{Finite Dimensional Representations}
We use the starting point of the Lie algebra of $SU(2)$: $[J_i,J_j]=i\hbar\epsilon_{ijk}J_k$. We want to know the representations of this algebra. But we note that the set $J_x,J_y,J_z$ is not the minimal set, since they don't all commute with one another, and the minimal set to describe the angular momentum Hilbert space will have commuting operators. So we form the Casimir $J^2=J_x^2+J_y^2+J_z^2$, which commutes with every component of $\vec{J}$. Canonically, then, we choose the minimal set to describe $\bb{H}_J=\{J^2, J_z\}.$ Using the diagonalizing states, we have $$J^2|jm\ra = \hbar^2j(j+1)|jm\ra, \ \ \ J_z|jm\ra=\hbar m|jm\ra.$$ We now note that the algebra fixes some properties of $j$ and $m$. First, we note that $J^2-J_z^2=J_x^2+J_y^2$ is a positive definite operator since one side is the sum of squares. This immediately implies that $$j(j+1)-m^2\geq 0,$$ which means that there are maximum and minimum values of $m$.

Now we define the operators $J_\pm=J_x\pm iJ_y$. With this, we have $[J_z, J_\pm]=\pm \hbar J_\pm.$ Now we see that $$J_z(J_\pm|jm\ra)=\hbar(m\pm 1)(J_\pm|jm\ra)\implies J_\pm|jm\ra = C_j^\pm |jm\pm1\ra.$$ So the movement of $m\in\bb{H}_J$ is in integer units, but we still don't know a starting position. So what are the minimum and maximum of $m$? We must have that $J_+|jmax\ra=0$ and $J_-|jmin\ra=0$. Therefore, $$||J_+|jmax\ra||=\la jmax|J_-J_+|jmax\ra=0.$$ But $J_-J_+=J^2-J_z^2-\hbar J_z$. So this in turn implies $$\hbar^2[j(j+1)-max(max+1)]=0\implies max=j, \ \ \ max=-j-1.$$ But we can't have the maximum be the negative answer, so the maximum is in fact $m=j$, and a similar argument for the other case shows the minimum is $m=-j$. So for fixed $j$, we've found the states go from $|j-j\ra\to|jj\ra$ in integer steps, and thus there are finitely many representations. Now, the algebra doesn't totally fix the values of $j$, but projecting to a wave function we would find that it has special azimuthal properties: it is either a single-valued (whole integer) number, or a doubly-valued (half-integer) number. I.e., the bosons and fermions. For a fixed $j$, there are $2j+1$ different states (or $m$ values). Now, rotations: $$\la jm'|D(\alpha\beta\gamma)|jm\ra=e^{-\frac{i}{\hbar}(m\gamma-m'\alpha)}\la jm'|e^{-i\beta J_y/\hbar}|jm\ra=D_{m'm}^j.$$ The matrix element in this definition is called $d_{m'm}^j(\beta)$. So we find the representation $$[D^j]=\left[\begin{matrix}
[d^{1/2}] & 0 & \dots\\
0 & [d^{1}] & \dots\\
\vdots & \vdots & [d^{3/2}]
\end{matrix}\right],$$ where the matrix of representations is block diagonal and the inner representations have increasing dimensions: $[d^{1/2}]$ is 2x2, $[d^1]$ is 3x3 and so on.


\section{Day 3: 1/30}

\subsection{Euler Rotation Representation}

We recall that $$\la jm|D(\alpha\beta\gamma)|jm'\ra=\la jm|e^{-i\alpha J_z/\hbar}e^{-i\beta J_y/\hbar}e^{-i\gamma J_z/\hbar}|jm\ra=e^{i(\alpha m-\gamma m')}\la jm|e^{-i\beta J_y/\hbar}|jm'\ra,$$ where the matrix element in the final equality is called $d_{mm'}^j(\beta)$, and is a $2j+1\times 2j+1$ block matrix. So the rotation matrix in the Euler representation is block diagonal, as shown yesterday (although the $[d^0]$ form (1 by 1) was omitted).

\subsection{Orbital Angular Momentum}

Recall we define $\bv{J}=\bv{L}+\bv{S}$, all operators. The $\bv{L}$ term is the orbital angular momentum, and lifting from classical mechanics we have $$\bv{L}=\posv\times\momv=\epsilon_{ijk}\pos_j\mom_k.$$ We know the canonical commutation relation $[x_i,p_j]=i\hbar \delta_{ij}$, which implies that $$[L_i,L_j]=\epsilon_{imn}\epsilon_{jpq}[x_mp_,x_pp_q]=i\hbar \epsilon_{ijk} L_k.$$ So these operators also obey the $SU(2)$ algebra, and so will its sum $J: [J_i, J_j]=i\hbar \epsilon_{ijk} J_k$. So we shouldn't be surprised that the set of operators $\{L^2,L_z\}$ completely span the set of outcomes in this Hilbert space, with the same form of diagonalizable elements: $$L^2|lm\ra = \hbar^2l(l+1)|lm\ra, \ \ \ L_z|lm\ra = \hbar m|lm\ra,$$ with $m\in[-l,l]$ increasing in unit steps. Again, there are $2l+1$ values of $m$ for each given $l$ value.

Now, in the $x$-representation, we consider a particle constrained to move on the $S^2$ manifold (the sphere). The location of the particle (for a sphere of fixed radius) is completely characterized by $\theta$ (the angle with respect to the $z$ axis), and $\phi$ (the angle about the axis between the poles). For such a system, the particles Hamiltonian is $$\Ham=\frac{L^2}{2I},$$ but the moment of inertia for a particle on a sphere is just $mR^2$. We set $R=1$ here. Thus we would have $$\Ham|lm\ra = E_l|lm\ra = \frac{\hbar^2l(l+1)}{2I}|lm\ra,$$ and we can see that these states have a degeneracy (since there are $2l+1$ substates with the same energy).

Now, the wavefunctions on $S^2$ are given by projecting the eigenstates into a certain basis: $\la \theta\phi|lm\ra = Y^m_l(\theta,\phi)$, and the explicit form is given by the spherical harmonics.

Note we have these eigenstates $$\la x | L^2|lm\ra = L^2(x)Y^m_l(x) = h^2l(l+1)Y_l^m(x),$$ for given coordinates $x$ (here polar). The $L^2(x)$ operator is just the Laplacian on the sphere: $$L^2(x)=\hbar^2 \left[\frac{1}{\sin\theta}\ptl_\theta \sin\theta \ptl_\theta + \frac{1}{\sin^2\theta}\partial_\phi^2\right],$$ with $R$ variables constants/set to 1, and $$L_z=\frac{\hbar}{i}\ptl_\phi.$$

As examples, for $l=0$, we have $Y_0^0(x)=\frac{1}{\sqrt{4\pi}}$ (found from integrating $\int dx |Y_0^0|^2=1$ on the sphere). For $l=1$, we have $Y_1^0(x)=C_0\cos\theta$ and $Y_1^{\pm 1}=C_{\pm}\sin\theta e^{\pm im\phi}$. In general, we have $$Y_l^m(\theta,\phi)=C_me^{im\phi}P_l^m(\cos\theta).$$ It is here where we see if increasing $\phi\to\phi+2\pi$ the single-valued and multivalued characteristics are important, since for fermions (with half-integer spin/projections) the exponent splits and returns a negative sign. For now we require that the wavefunctions be single-valued, and so the whole-integer spin case (bosons) are what we consider.


Since these are rotationally invariant functions(?), there must be a relation between $Y_l^m$ and $D_{mm'}^l$. We note that $Y_l^m=\la x|lm\ra = \la lm|x\ra^\dagger$, where $|x\ra$ can be obtained by a Euler transformation on the $\hat{z}$ axis: $|x\ra = R(\phi,\theta,0)\hat{z}$. So $$Y_l^m(x)=\la lm|R\hat{z}\ra^\dagger=\la lm|D(R)|z\ra^\dagger=\sum_{lm'}\la lm|D(R)|lm'\ra\la lm'|\hat{z}\ra^\dagger=D_{mm'}^l(\phi,\theta,0)Y_l^{m'}(\hat{z}).$$

But along $\hat{z}$, both $\theta=\phi=0$. So $Y_l^{m'}(0,0)=\delta_{m'0}[Y_l^0(0,0)=P_l^0(\cos 0=1)]=\delta_{m'0}\sqrt{\frac{2l+1}{4\pi}}P_l(1)$. So $$Y_l^{m}(\theta,\phi)=D_{m0}^l(\phi,\theta,0)\sqrt{\frac{2l+1}{4\pi}}P_l(1).$$

\subsection{Addition of Angular Momentum}

Suppose we have two $J_1, J_2$ such that $J=J_1+J_2$. How do we represent the Hilbert space for the composite system? We note that $\{J_1^2, J_{1z};J_2^2,J_{2z}\}$ forms a complete set for one aspect of it. But we also know that the total angular momentum is conserved, and so are the components: $\{J_1,J_2;J^2, J_z\}$ also form complete bases: because $[J^2, J_i]=0$ and also the other two (??). So we have two representations: $$|J_1J_2;m_1m_2\ra \leftrightarrow |J_1J_2;J m\ra,$$ related by a unitary transformation since both are complete. The transformations between them are given by the Clebsch-Gordon coefficients and the inverse transformations as well: \begin{align*}|J_1J_2;m_1m_2\ra &= \left[\sum_{1,2}|J_1J_2;Jm\ra\la J_1J_2:Jm|\right]|J_1J_2;m_1m_2\ra,\\|J_1J_2;J m\ra &= \left[\sum_{j,m}|J_1J_2;m_1m_2\ra\la J_1J_2:m_1m_2|\right]|J_1J_2;Jm\ra,\end{align*} where the first summation is restricted by requiring $m_1+m_2=m$ (with $J_1,J_2$ fixed) and the second is restricted by the same as well as $|J_1-J_2|\leq J \leq |J_1+J_2|.$ (NOTE: the summation indices he wrote in class look wrong.)

\subsection{Vector Operators}

We've more or less finished looking at the rotation group, so now we'll look at how operators react to rotations to build up an understanding of how their measurements are affected. We will build up to the Wigner-Eckart theorem, and how symmetries give us very important physical consequences.

We denote a vector operator $\vec{V}$ in terms of its components $V_i$, where $i$ can be Cartesian (1,2,3 or $xyz$) or in some cases $0,\pm$ (for spherical coordinates). We note in a measurement, we usually look for the expectation value, so from rotated states we get $$_R\la\alpha|V_i|\beta\ra_R = \la \alpha|D^\dagger(R)V_iD(R)|\beta\ra = R_{ij}\la \alpha|V_j|\beta\ra.$$ So the rotated expectation value is the same as the similarity transformed matrix element of the operator: $$D^\dagger V_i D = R_{ij}V_j.$$

Under infinitesimal rotations, we have $$(\Id+\frac{i\epsilon}{\hbar}\vec{J})V_i (\Id-\frac{i\epsilon}{\hbar}\vec{J})=\left(\Id-\frac{i\epsilon}{\hbar}\cdot G\right)_{ij}V_j,$$ where $\vec{J}$ are the operators that generate the rotation.

From this we see (?) that $[\vec{\epsilon}\cdot\vec{J}, V_i]=i\hbar (\vec{\epsilon}\cdot \vec{G})_{ij} V_j$ (????????).

Similarly, $$[J_m, V_i]=i\hbar (G_m)_{ij}V_j, \ \ (G_m)_{ij}=\epsilon^{imj}=-\epsilon_{imj}=\epsilon_{mij}.$$ So $$[J_m, V_i]=i\hbar \epsilon_{mij}J_j.$$

(What the fuck?)






\section{Day 4: 2/1}


As an addendum to a question somebody asked yesterday, he discussed the translation group and how it's not completely isomorphic to the circle. He mentioned it was an element of $U(1)$ when in fact it's more akin to an element of $E(D)$ (the flat group of Euclidean transformations).


\subsection{Vector Operators}

Angular momentum, spin, position, and momentum operators are examples. The rotational symmetry (group) allows us to classify not only the states in $\bb{H}$, but also the measurements we can make.

We consider a vector operator $V$ indexed by $i$: $V_i$. Under rotation, we have $D^\dagger V_i D=R_{ij}V_j$, or the measurement operator is just rotated. This can also be seen from $$_R\la \alpha|V_i|\beta\ra_R = \la \alpha|D^\dagger V_iD|\beta\ra = R_{ij}\la V_i \ra,$$ since we usually just measure the expectation value. That is, the rotated states expectation value is equivalent to the expectation value of the rotated measurement.


\subsection{Spherical Harmonics}

How would the spherical harmonic states $Y_l^m(\pos)$ be affected under rotation? (Here, $\pos$ is the coordinate choice of our representation, i.e. $\theta$ and $\phi$). Recall that an operator acting on a function is the same as the operator acting on the coordinates of the function: $$\left(Y_l^m(\pos)\right)^R = Y_l^m(R\pos)=\la R\pos|lm\ra = \la lm|R\pos\ra^\dagger=\la lm |D|\pos\ra ^\dagger.$$ We introduce a complete set to sum over, so that $$\left(Y_l^m(\pos)\right)^R = \sum_{lm'} \la lm|D|lm'\ra \la lm'|\pos\ra^\dagger=\sum_{m'}D_{mm'}^{l\dagger}Y_l^{m'}(\pos)\equiv D_{mm'}^{l\dagger}Y_l^{m'}(\pos),$$ where the final equality holds because of implicit summation over the $m'$ index. So this is how the spherical harmonics change under rotation in space.

Note: we can look at the spherical harmonics of ``rank" one (i.e. $l=1$) $$Y_1^m\leftrightarrow (Y_1^{-1}, Y_1^0,Y_1^{+1})\propto (e^{-i\phi}\sin\theta,\cos\theta,e^{i\phi}\sin\theta)=\left(\frac{x-iy}{r},\frac{z}{r},\frac{z+iy}{r}\right).$$ The spherical harmonics for $l=1$ form a vector, written in a spherical basis. Under rotation, we know how it transforms but we also know that the spherical harmonics are the basis set that diagonalizes the rotation group. Because the vector operators are generalized forms of vectors, here, we can organize them the same way as the spherical harmonics $Y_l^m$, and expect similar transformations: $(Y_l^m)^R=D_{mm'}^lY_l^{m'}$ (with implicit summation).

\subsection{Tensors}

In ``classical space", we know how tensors behave. We examine them here so we can lift them to quantum mechanical regimes. For example, a quantum tensor would be some kind of deformation in the system (for example, a quadrupole). We call rank-1 tensors vectors, indexed by one index: $T_i$. Rank-2 tensors have two indices, rank-3 have three and so on: $T_{ij}, T_{ijk}$. Under rotation, each index transforms separately: $(T_{ij})^R=R_{ii'}R_{jj'}T_{i'j'}.$ For a rank-2 tensor, with indices ranging from $i,j=1\to d$, it forms a $d\times d$ matrix (classically). We note we can decompose any such tensor into $$T_{ij}=\frac{1}{3}\delta_{ij}T+\frac{1}{2}\left(T_{ij}-T_{ji}\right) +\left\{\frac{1}{2}\left(T_{ij}+T_{ji}\right)-\frac{1}{3}\delta_{ij}T\right\},$$ where $T$ is the trace of the tensor. The first term has only one independent value ($T$), the second is antisymmetric and has $3$ independent values, while the third is symmetric and traceless, so thus has only 5 independent values. So $T_{ij}$ is characterized by 9 numbers, as we would expect given its $3\times 3$ matrix form. If we apply the rotation to this decomposition, each term transforms independently and its symmetric structure is preserved (i.e., the diagonal term is invariant, the antisymmetric is antisymmetric and so on).

So $\delta_{ij}$ term is effectively a spin-0 term (only one independent variable), and using the $2j+1$ rule the others are like spin-1 and spin-2. The ranks behave as though we were vector adding smaller ranks to each other.

In quantum mechanics, we require the irreducible operators to transforms as the $Y_l^m$ states do.

The moral here is that we can decompose a reducible tensor of some rank into a tensor sum $$[T]=\sum_k[T^k],$$ where the dimensions of the decomposed ranks add up to the dimension of the initial.

\subsection{Irreducible Tensor Operators}

The defining characteristic we require is that $$\left(T^k_q\right)^R=D^\dagger T_q^k D = D_{qq'}^{k\dagger}T_{q'}^k,$$ or they transform under rotations as the spherical harmonics do. Here $k$ is the rank of the tensor and $q$ is an entry. That is, we can organize measurements into blocks whose symmetries/ranks are unchanged under rotations. In infinitesimal form, we have $$\left(\Id+\frac{i}{\hbar}\vec{\epsilon}\cdot\vec{J}\right)T_q^k \left(\Id-\frac{i}{\hbar}\vec{\epsilon}\cdot\vec{J}\right) = \la kq|D|kq'\ra^\dagger T_{q'}^k=\la kq| \left(\Id+\frac{i}{\hbar}\vec{\epsilon}\cdot\vec{J}\right) | kq'\ra^\dagger T_{q'}^k.$$ Matching to order $\epsilon$, we find that $$[\vec{\epsilon}\cdot\vec{J},T_q^k]=\la kq' | (\vec{\epsilon}\cdot\vec{J})^\dagger|kq\ra T_{q'}^k.$$ We can introduce a new variable to match $J_+,J_-$: $\epsilon_{\pm}=\frac{1}{2}(\epsilon_x\pm i\epsilon_y)$. That way, we can choose one, say $\epsilon^-J_+$ so expand in. This eventually leads to $$[J_\pm, T_q^k]=\hbar \sqrt{k(k+1)-q(q\pm 1)} T^k_{q\pm 1}.$$ The irreducible representation of rank-k moves by one unit.

\subsection{Composition of Irreducible Representations}

Suppose we have irreducible representations of ranks $k_1$ and $k_2$. We can construct another tensor with the tensor product that is itself irreducible (similar to adding angular momentum).

We define $$X_q^k = \sum_{[1,2]} \la k_1 k_2 q_1'q_2'|k_1k_2 q_1q_2\ra X_{q_1'}^{k_1}X_{q_2'}^{k_2}.$$ The $k$ values add like vectors, with the resulting answer having $|k_1-k_2|\leq k\leq k_1+k_2$, and with $q=q_1+q_2$. Those restrictions apply to the summation. It was proven in class that this $X_q^k$ is irreducible (transforms as the spherical harmonics).


\section{Day 5: 2/6}

\subsection{Wigner-Eckart Theorem}
We recall that the irreducible tensors in a spherically symmetric basis transform like the $Y_l^m$ spherical harmonics, and tensors of different rank compose as though their ranks were added like angular momenta.

Suppose we have a tensor operator of rank $k$: $T_q^k$. We want to know what the matrix element $$\la \alpha'j'm'|T_q^k|\alpha j m\ra$$ would be in this $2j+1\times 2j+1$ matrix. Here, the $\alpha$ quantum numbers are any quantum number, and the $j,m,j',m'$ are "spin" quantum numbers (generalized angular momenta), which relate to the $kq$ values. We compose the $k$ and $j$ values to get $j'$ values as though adding angular momenta: $\vec{k}+\vec{j}=\vec{j}'$, with the usual restrictions $|j-k|\leq j' \leq j+k$ and $m'=q+m$. The theorem is as follows: \begin{mdframed}
	$$\la \alpha'j'm'|T_q^k|\alpha j m\ra = \la jkmq|jkj'm'\ra \frac{\la \alpha' j' ||T^k||\alpha j\ra}{\sqrt{2j+1}}$$
\end{mdframed} That is, the symmetry dependence separates: all of the azimuthal information is held in the Clebsch recoupling constant, and all of the dynamics information (now independent of azimuth) is held in the normalized irreducible matrix element, which must be found by the Schrodinger equation. What is interesting about this is that if we measure an operator in that basis, all outcomes are fixed by the symmetry (in that the Clebsch coefficients determine it up to an overall number). For example, for $j=1$, we have a $3\times 3$ matrix of unknown values. Even though we don't know them all, given a single one we can predict everything else without solving the Schrodinger equation. The matrix element on the right is sometimes referred to as the generic charge $g^k$, and we note the Clebsch coefficient is of the form $\la j_1j_2 m_1m_1|j_1j_2jm\ra$, for $j_2=k$ and $m_2=q$.

The proof of the theorem recalls $$[J_\pm,T_q^k]=\hbar C_{kq}^\pm T_{q\pm 1}^k,$$, where $C_{kq}^\pm = \sqrt{k(k+1)-q(q\pm 1)}$. Since the tensor transforms as the spherical harmonics (i.e. $D^\dagger T_q^k D=D^{k*}_{qq'}T_{q'}^k$), we take the matrix element of, say, the raising operator: \begin{align*}
\la \alpha'j'm'|[J_+,T_q^k]|\alpha j m\ra &= \la \alpha'j'm'| J_+T_q^k|\alpha jm\ra - \la \alpha'j'm'|T_k^q J_+|\alpha j m\ra \\
&=C^-_{j'm'}\hbar \la \alpha'j'(m'-1)|T_q^k|\alpha jm\ra-C_{jm}^+\hbar \la \alpha'j'm'|T_q^k|\alpha j (m+1\ra)\\
&= \hbar C_{kq}^k\la \alpha'j'm'|T_{q+1}^k|\alpha jm\ra.
\end{align*} Now we note the Clebsch coefficients themselves satisfy a similar relation: $$C_{kq}^+\la jkm(q+1)|jkj'm'\ra = C_{j'm'}^- \la jkmq|jkj'(m'-1)\ra - C_{jm}^+\la jk(m+1)q|jkj'm'\ra,$$ so this combined with the above equality implies $$\la \alpha'j'm'|T_q^k|\alpha jm\ra = \#\la jkmq|jkj'm'\ra,$$ thus "establishing" the result.

\subsection{Discrete Symmetries}
We note in classical mechanics, continuous symmetries such as translations $T_{\vec{x}}$, rotations $R_{\vec{x}}$, and inversions $I_{\vec{x}}$ were discussed (minus inversions). Some discrete symmetry examples include discrete translation $T_{\vec{a}}$, parity $P_{\vec{x}}$, and time reversal $T_t$.

In the classical continuous case, symmetries are often found in invariances in the Lagrangian $L(x,\dot{x},\dots)$. For example, if $L$ is invariant under translations (i.e. $\ptl_x L=0$), then $\ptl_t(\ptl_{\dot{x}}L)=0$, where we identify $\ptl_{\dot{x}}L\equiv p_x$, and we say the canonical momentum is conserved. So symmetries classically encode conservation laws.

In quantum mechanics, conserved charges from an operator $Q$ yield $$i\hbar \frac{d}{dt}Q=[Q,\Ham]=0,$$ where $Q$ is associated with a unitary operator $D=e^{-iqQ/\hbar}$ that is generated by its conjugate variable. For example, $Q=\mom$ gives $D(x)=e^{-ix\mom/\hbar}$. The commuting operator and Hamiltonian yield conserved charges, but this is not generally the case in discrete symmetries. Instead, discrete symmetries are typically associated to selection rules among quantum numbers.

\subsection{Parity}

In classical mechanics, we have $P_x\vec{x}=-\vec{x}$. Note that $P_x^2\vec{x}=\vec{x}$, or that $P_x^2=\Id$.

In quantum mechanics, we have a similar notion: the parity operator $\Pi$ acts on an abstract state $\Pi|\psi\ra$, but under the same conditions. We require unitarity for probability conservation $\Pi^\dagger\Pi=\Id$, but also the same squared requirement $\Pi^2=\Id$, which is the characteristic of a projection operator. Now we have $\Pi=\Pi^{-1}=\Pi^\dagger$.

Because $\Pi^2=1$, we note the eigenvalues can only be $\pm 1$: $$\Pi|\psi_\pm\ra = \lambda_\pm|\psi_\pm\ra\implies \lambda^2_\pm=1\to \lambda_\pm = \pm 1$$

Now parity symmetry in quantum mechanics means that $[\Pi,\Ham]=0$. Even with no "charge" to associate with it, we can still characterize the states and eigenvalues related to it. By simultaneously diagonalizing $\Ham$ with $\Pi$, we can get $$\Ham|\psi_{n,\pm}\ra = E^n_\pm|\psi_{n,\pm}\ra, \ \ \ \Pi|\psi_{n,\pm}\ra = \pm |\psi_{n,\pm}\ra.$$ The energies might be degenerate if they don't depend on the parity, but they also might not be.

We take for an example $\Ham=\frac{L^2}{2I}$, for a particle on a sphere. Note that $L^2$ is the spherical Laplacian, which is claimed to be symmetric under the parity exchange of its variable. So $$\Ham|lm\ra = \frac{\hbar^2l(l+1)}{2I}|lm\ra$$ and $\la \hat{x}|lm\ra = Y_l^m(\hat{x})$. We see $$\left(Y_l^m(\hat{x})\right)^\Pi = \la \hat{x}|\Pi|lm\ra = \la -\hat{x}|lm\ra=Y_l^m(-\hat{x}).$$ But $Y_l^m(-\hat{x})=Y_l^m(\theta+\pi,\pi-\phi)$ (somehow. Issues with domain definition and not very clear derivation in class). So $$Y_l^m(-\hat{x})=Y_l^m(\theta+\pi,\pi-\phi)=\# e^{im(\pi-\phi)}P_l^m(\cos(\theta+\pi))=\# (-1)^me^{-im\phi}(-1)^{l+m}P_l^m(\cos\theta)$$, which reduces to $$Y_l^m(-\hat{x})=(-1)^lY_l^{-m}(\hat{x}).$$ So the parity changes from shell-to-shell, with even $l$ having even parity.

As a second example, we consider $\Ham=p^2/2m$ with an infinite square well potential having walls at $x=\pm a$. Classically, $V(x)=V(-x)$. Now $$\Ham|n\ra = \frac{1}{2m}\left(\frac{\hbar\pi n}{2a}\right)^2, \ \ \ \phi_n(x)=\frac{1}{\sqrt{2a}} \sin\left(\frac{n\pi}{2a}(x+a)\right), \ \ n\in \bb{Z}_{>0}.$$ Under parity transformation, $$\phi_n^\Pi(x)=\phi_n(-x)=\frac{1}{\sqrt{2a}}\sin\left(\frac{n\pi}{2a}(-x+a)\right)=\frac{1}{\sqrt{2a}}\sin\left(\frac{n\pi}{2a}(-x-a+2a)\right),$$ which reduces the argument to $$\sin\left(\frac{n\pi}{2a}(-x+-a)+n\pi\right).$$ We can account for the phase shift and negative sign to find $$\phi_n^\Pi(x)=(-1)^{n+1}\phi_n(x),$$ where again we find the parity is relevant to the main quantum number.

\section{Day 6: 2/8}

\subsection{Discrete Translational Symmetry}

We recall the translation operator shifts states in space. Discrete translation operators shift by unit $a$ in a given dimension. Like continuous, they must be unitary to preserve probability: $T_a^\dagger T_a=1$. By a similar derivation, $$\la x|T_a|\psi\ra = \psi(x-a)=e^{-aD}\psi\implies T_a=e^{-aD}=e^{-ia\mom/\hbar}.$$

A new feature, however, is given by the Bloch theorem. If we have a discrete symmetry (i.e., suppose a periodic potential with period $a$), then $[T_a,V(x)]=0$ because $T_a^\dagger V(x)T_a=V(x+a)=V(x)$ (?). So if the Hamiltonian is just a kinetic plus potential part, $\Ham=K+V$, then $[T_a,\Ham]=0$. \begin{mdframed}
	Given the above, the wavefunction of this Hamiltonian is quasiperiodic: $$\psi(x+a)=e^{ika}\psi(x).$$
\end{mdframed} We have a corollary, where we can make the wavefunction in this periodic potential purely times a phase: $$\psi(x)=e^{ikx}U_k(x),$$ where $U_k(x)$ is purely periodic.

To prove the theorem, we have that $[T_a,\Ham]=0$ so they are simultaneously diagonalizable. So we have $E$ from $\Ham$ and $\lambda_a$ from $T_a$. Note that because all states live in the Hilbert space, $||\psi_a||<\infty$ because $||\psi||<\infty$. Thus $$T_a^N|\psi\ra = \lambda_a^N|\psi\ra$$ must imply that both $||\lambda_a||^N$ and $||\psi||$ are less than infinity. Immediately this means that $\lambda_a$ is finite, but for non-vanishing wavefunction as $N\to \infty$ it must be that $||\lambda_a||^N=1$, so we write $$\lambda_a=e^{-iak}\to T_a|\psi\ra = e^{-ika}|\psi\ra\implies \psi(x+a)=e^{ika}\psi(x),$$ as we stated. Note: defining $U_k(x)=e^{-ikx}\psi(x)$ and examining $U_k(x+a)$ establishes the corollary. We have $k$ with units of inverse length, and we call $k$ the quasimomentum in the crystal.

As an example, we consider $C_6H_6$ (benzene), which has $T_a\to R_{\pi/3}$ "translational" symmetry. Breaking the ring structure gives an infinitely periodic line along which to translate, hopping from carbon to carbon. We have $\Ham|\psi\ra = E|\psi\ra$ and $R_{\pi/3}|\psi\ra=\frac{1}{\lambda}|\psi\ra$, where we recall that $\lambda$ is just a phase so having it on the denominator or numerator just changes the imaginary exponent sign. We solve this using the tight bond approximation. 

That is, we assume at every site of periodicity (the carbon atoms), we think of $C$ as heavy and $H$ as light, so that the hydrogens sit in the carbons potential minima. Tight bonding implies that the wavefunctions of each don't talk to teach other (to zeroth order), but we will allow for nearest-neighbor communication only. We have states $|n\ra$ where $n=1\dots 6$, and $\la n|m\ra=\delta_{nm}$ due to orthonormality (again to zeroth order). We have $$(T_a=R_{\pi/3})|n\ra=|n+1\ra, \ \ \ |\psi\ra=\sum_{n=1}^6 \lambda^n|n\ra,$$ where the coefficients could be arbitrary but will end up being $\lambda^n$. The Hamiltonian in this approximation is a $6\times 6$  banded matrix, of the form $$\Ham=\sum_{n=1}^{6}\left[E_o|n\ra\la n| - \Delta|n+1\ra\la n| - \Delta|n\ra\la n+1|\right].$$ We have $$R_{\pi/3}|\psi\ra=\sum_n \lambda^n R_{\pi/3}|n\ra = \frac{1}{\lambda}\sum_{n+1}\lambda^{n+1}|n+1\ra=\frac{1}{\lambda}|\psi\ra,$$ where we relabel the indices for equality. Now, since $\lambda^N=1$, we have $$\lambda=e^{-i2\pi q/N}, \ \ \ q=1,\dots, N, \ \ N= \frac{-N}{2},\dots,\frac{N}{2}, \dots$$ where we can choose how to index $q$. Solving for $E$ and using the orthonormality gives $E=E_o-\Delta\lambda -\frac{\Delta}{\lambda}$ term-by-term, and given we know $\lambda$ we get $$E_q=E_o-2\Delta\cos\left(\frac{2\pi q}{N}\right).$$ So the energy depends on the quasimomentum state. The energy levels have 6 discrete levels, where $-3<q\leq 3$ using the half-integer counting above, which lie on a cosine distribution. For large $N$, we can expand the cosine function to see $$E_q=E_o-2\Delta +\frac{1}{\frac{1}{\Delta a^2}}\left(\frac{2\pi q}{Na}\right)^2+\dots,$$ where we've inserted factors of $a$ into the expanded term. Now the coefficient $(1/\Delta a^2)^{-1}$ is like an effective mass for the effective momentum term it weights. So here we see the overlap of the wavefunctions is a source of intertia.

For large $N$, the spacing between $q$ points becomes very small, eventually leading to a continuous dispersion relations $E$ vs. $P_{eff}$. In an infinite lattice/crystal, the dispersion relation (say, for $e^-$) is given by $$E_q\overset{N\to\infty}{\to}E_o-2\Delta\cos(p_qa), \ \ \ p_q=\frac{2\pi q}{Na}.$$

\subsection{Time Reversal Symmetry}

This will be the first and last example in our class of an antiunitary operator. In classical mechanics, the Newtonian force (in absence of friction) gives $m\ddot{x}=F$, which under $t\to-t$ is invariant due to its second order time dependence. That is, if $x(t)$ is a solution then so is $x(-t)$. However, including velocity dependent terms, say $m\ddot{x}=e(\dot{x}\times \vec{B})$ would not be symmetric under time reversal unless the sign of $\vec{B}$ changes as well.



\section{Day 7: 2/13}

\subsection{Time Reversal Symmetries}

Recall in classical mechanics, Newton's equation being second order with respect to time means it is symmetric under $t\to -t$. That is, given an initial condition to $m\ddot{x}=-\ptl_xV$ that yields a solution $x(t)$, $x(-t)$ is also a solution. This isn't true for, say, the trajectory under a magnetic field, due to the first order appearance $\dot{x}$: $m\ddot{x}=e\dot{x}B$ (schematically). Under $t\to -t$, the system is not invariant, but one must also change $B\to-B$ as well. However, if $\vec{B}$ is produced dynamically \textit{by} the trajectory $x(t)$, switching $t\to -t$ switches the current direction, thus the direction of the produced magnetic field. In such cases, the time reversal is a symmetry. However, in externally applied magnetic field scenarios, it is not.

Now, in quantum mechanics, we have a first order time dependence in the Schrodinger equation $i\hbar \dot{\psi}(x,t)=H(x,\nabla)\psi(x,t)$. Moving $t\to -t$ gives $$-i\hbar \dot{\psi}(x, -t)=H(x,\nabla)\psi(x,-t).$$ But we can reabsorb the negative into the $i$, so get $i\hbar\dot{\psi}^*(x,-t)=H(x,\nabla)\psi^*(x,-t).$ So the symmetry here is with respect to time reversal and conjugation. But the conjugation takes you out of $H$ and puts you in the dual space $H^*$, i.e. moves you from a ket to a bra. This is different than the unitary case before, where you remained in the original space. Because of this, time reversal is anti unitary.

\subsection{Wigner Theorem}

We recall that we thought of symmetries as encoded by invariant probabilities (or norm invariance) under the action of an operator (which forced unitarity). The Wigner theorem states that in quantum mechanics, not only must the norm be preserved but the general measure must be as well (of which the norm is a special case). That is, $|\la \alpha|\beta\ra|$ is invariant (where we use the absolute value signs because the measure is complex, generally).

Say $S|\alpha\ra = |\tilde{\alpha}\ra$. Thus it must be that $|\la \alpha|\beta\ra|=|\la \tilde{\alpha}|\tilde{\beta}\ra |$. This can either lead to the unitary case: $$\la \alpha|\beta\ra = \la \tilde{\alpha}|\tilde{\beta}\ra = \la \alpha|S^\dagger S|\beta\ra\implies S^\dagger S=\Id,$$ or the antiunitary case where $$\la \alpha|\beta\ra = \la \tilde{\beta}|\tilde{\alpha}\ra=\la\beta|S^\dagger S|\alpha\ra,$$ up to some phase to make the absolute value the same. The second statement does not imply unitarity, but antiunitarity because of the conjugation of the states.

We let $S=\Theta$ for the time reversal operator, and we will see its antiunitary nature. For unitary operators, when making a measurement $\la \tilde{\alpha}|A|\tilde{\beta}\ra = \la \alpha|U^\dagger A U|\beta\ra$, implying that $A\to U^\dag AU$. The measurements in the presence of unitary transformations are linearly related.

We wish to examine the relationship between measurements with $\Theta$. How does $\la \alpha|A|\beta\ra$ relate to the measurement in the transformed basis? First, we let $|\gamma\ra = A^\dagger|\alpha\ra$, so that $$\la \alpha|A|\beta\ra = \la \gamma|\beta\ra.$$ By the Wigner theorem, we have (up to a phase) $$\la \gamma|\beta\ra = \la \tilde{\beta}|\gamma\ra=\la\tilde{\beta}|\Theta|\gamma\ra = \la\tilde{\beta}|\Theta A^\dag \Theta^{-1}|\tilde{\alpha}\ra.$$ This is almost like the unitary case, but the operator is conjugated and the entries are flipped. (But for observables $A=A^\dagger$.) Here we can't disengage the states, due to the flipping of the bra and ket.

As some example, $\mom\to -\mom$ under $\Theta\mom\Theta^{-1}$ (due to the first order time dependence) in the changed basis. Additionally, $\pos\to\pos$ and $L\to -L$ (or $S\to-S$).

On wavefunctions, we have $\psi(x)\to \psi^*(x)$ as we've seen, and $$Y_l^m(\hat{x})\to Y_l^{m*}(\hat{x})=\pm Y_l^{-m}(\hat{x}).$$ In the basis free form, we have $$|\tilde{lm}\ra = \Theta|lm\ra = (-1)^m|l(-m)\ra, \ \ \ |\tilde{x}\ra = |x\ra.$$

\subsection{Spin-1/2 Representation}

We want the specific representation in this basis and since the operator is inside a 2-component Hilbert space we expect $\Theta$ to be a 2 by 2 matrix.

We first start with a generally oriented $S_n|+\ra_n=+\hbar/2|+\ra_n$. Spin is like angular momentum, and we've seen how those states change above: $$\Theta|+\ra_n = \Theta\left|\frac{1}{2}\frac{1}{2}\right\ra_n=\eta\left|\frac{1}{2}\frac{-1}{2}\right\ra_n, \ \ \ \eta\in\bb{C}: |\eta|=1.$$

This was along a general direction, but as always we can construct this direction as rotations about the $y$ axis by $\beta$ then the $z$ axis by $\alpha$: $$\Theta|+\ra_n = \Theta\left[e^{-i\alpha S_z/\hbar}e^{-i\beta S_y/\hbar}\right]|+\ra_z = \Theta\left[e^{-i\alpha S_z/\hbar}e^{-i\beta S_y/\hbar}\right]\Theta^{-1}\Theta|+\ra_z.$$

Because $\Theta^{-1}\Theta=\Id$, we can always exponentiate it, recalling that moving across a scalar conjugates it and that $S_i$ are odd under the action of time reversal. So $$\exp\left(-\left[+\frac{i\alpha \Theta S_z \Theta^{-1}}{\hbar}\right]\right)\exp\left(-\left[+\frac{i\beta \Theta S_y \Theta^{-1}}{\hbar}\right]\right)\to e^{-i\alpha S_z/\hbar}e^{-i\beta S_y/\hbar},$$ resulting in what we started with. Thus $$\Theta|+\ra_n = e^{-i\alpha S_z/\hbar}e^{-i\beta S_y/\hbar}\Theta|+\ra_z.$$ But we know that $\Theta|+\ra_n=\eta|-\ra_n$, which we can also realize by increasing the $y$-axis rotation to $\beta+\pi$. Thus $$\eta|-\ra_n=\eta e^{-i\alpha S_z/\hbar}e^{-i(\beta+\pi) S_y/\hbar}\Theta|+\ra_z\implies \Theta = \eta e^{-i\pi J_y/\hbar}\vec{k},$$ where the $\vec{k}$ just complex conjugates what it acts on to the right. This is just regular complex conjugation, not Hermitian conjugation. Note: $\eta$ is a phase, so $|\eta|=1$, and $\vec{k}$ is just conjugation so $k^2=\Id$. For a spin-1/2 particle, $$\Theta = \eta (-i\sigma_y)\vec{k},$$ which is a 2 by 2 matrix as we expected. This is not Hermitian or unitary due to the presence of $\vec{k}$.

We note a feature of $\Theta$ symmetry in the spin-1/2 shell is that $\Theta^2\neq \Id$, but instead is $-\Id$. Thus to reach the original state, you must reverse time four times. This is a feature of all half-integer spin configurations: $$\Theta^2=(-1)^{2s}.$$

For arbitrary angular momentum, we know that $\Theta|jm\ra = (-1)^m |j (-m)\ra.$ In fact, the spin-1/2 argument generalizes completely because we never used the dimensionality until invoking the explicit matrix form. Thus, $$\Theta = \eta e^{-i\pi J_y/\hbar}\vec{k}, \ \ \ J_y=L_y+S_y.$$ Thus $$\Theta|jm\ra = (-1)^m |j(-m)\ra, \ \ j=l+m \implies \Theta^2|jm\ra = (-1)^2m|j(-m)\ra.$$ This gives us the spin-1/2 result, and shows for integer spin configurations that $\Theta^2=\Id$.

\subsection{Kramer's Theorem}

Suppose $\Ham$ is symmetric under time-reversal measurements: $$\Ham\to \Theta\Ham^\dagger\Theta^{-1}=\Ham,$$ because $\Ham$ is hermitian. We know the time translation operator $U(t)=e^{-i\Ham t/\hbar}$, but we see that it is not symmetric under time translation measurements: $$U(t)\to \Theta U^\dagger(t) \Theta^{-1}\neq U(t),$$ since even though $\Theta$ might commute, $U^\dagger(t)\neq U(t)$. Even if time translation is a symmetry of the Hamiltonian, there is no corresponding conserved charge in time. But there may still be selection rules.

The theorem is as follows: take a spectrum $\Ham|n\ra = E_n|n\ra$, where we assume $\Ham$ has time reversal symmetry. Then naively we assume $\Theta|n\ra = \xi |n\ra$, since we can simultaneously diagonalize the two operators. Now: $$\Theta^2|n\ra = \Theta(\Theta|n\ra)=\Theta(\xi|n\ra)=\xi^*\Theta|n\ra = |\xi|^2|n\ra,$$ since $\Theta$ conjugates the things it acts on. This immediately implies that the half-integer spin states are degenerate, since $\Theta^2$ would return the negative state, and $|\xi|^2$ can't be negative, so this does not apply to them. I.e., they cannot be simultaneously diagonalized.

\subsection{3D Problems}

Most are difficult to solve (analytically), except for a few. We begin with rotationally symmetric problems, such that $$\Ham=\frac{\mom^2}{2m}+V(\pos = r),$$ and $[D(R),\Ham]=0$. Whenever this is true, we can split the problem into a free part and a potential part: $$\Ham\to \Ham = \Ham_r+\Ham_{S^2}+V(r),$$ where we write $$\Ham_r = \frac{1}{2m}\left(\frac{\hat{r}\cdot\mom + \mom\cdot\hat{r}}{2}\right)^2, \Ham_{S^2} = \frac{\hat{L}^2}{2m\hat{r}^2}=\frac{(\pos\times\mom)^2}{2m\hat{r}^2}.$$ That is, we split the kinetic term into a radial portion and a rotational portion. The term $\Ham_r$ was written in that way so as to make it Hermitian. The free part will be separable, and will have solutions $R(r)Y_l^m(\pos)$, where $R(r)$ will be Bessel functions of some sort. In general, these states will be labeled $|nlm\ra$, and the potential term can then be solved for in terms of superpositions of the complete basis set. The stationary problem, then: $$\left[\Ham_r+\Ham_{S^2}+V(r)\right]\psi(\vec{x})=E\psi(\vec{x})\to \psi(\vec{x})=\sum_{nlm}c_{nlm}R_{nlm}(r)Y_l^m(\pos).$$ By explicitly determining $\la nlm|V|n'l'm'\ra$, the problem becomes a linear matrix problem in diagonalization: $$[\Ham][C]=E[C].$$

\subsection{The Coulomb Problem}

We assume $V(r)=\frac{-e^2}{r}$, modeling, for example, the hydrogen atom. We assume the proton is sufficiently heavy as to not move, thus the electron is just orbiting around a fixed point ($m_e/m_p\ll 1$). Then we have $$\left[-\frac{\hbar^2}{2m}\left(\frac{\ptl}{\ptl r^2}+\frac{2}{r}\frac{\ptl}{\ptl r}\right)+\frac{l(l+1)\hbar^2}{2mr^2}-\frac{e^2}{r}\right]\psi(\vec{x})=E\psi(\vec{x}),$$ where when we write $$\frac{\mom^2_r}{2m}=-\frac{\hbar^2}{2m}\left[\frac{-1}{r^2}\ptl_r r^2 \ptl_r = \frac{\ptl}{\ptl r^2}+\frac{2}{r}\frac{\ptl}{\ptl r}\right]$$ makes it evident that the operator is Hermitian.

\section{Day 8: 2/15}

The midterm will be in the first week of March and will include perturbation theory topics.

\subsection{Coulomb Problem}

This is a "simple" example of a 3D problem with rotational symmetry. We consider an electron orbiting a nucleus, and consider the nucleus to be heavy enough to be stationary ($m_e/m_p\ll 1$). We have $$\Ham=\frac{\momv^2}{2m}-\frac{e^2}{r},$$ using the Coulomb potential. We note that since this is a radial problem (i.e., the potential is radial), we have $[D(R),\Ham]=0$, and since these rotations are spatial in nature we have $[\vec{L},\Ham]=0$. So we can simultaneously diagonalize: $$|\psi\ra = |R\ra |lm\ra \to \Ham|\psi\ra = E|\psi\ra, L^2|\psi\ra = \hbar^2l(l+1)|\psi\ra, L_z |\psi\ra = \hbar m|\psi\ra.$$ We could choose the basis of the free particle and diagonalize the huge matrix by finding the potential matrix entries (as briefly mentioned yesterday), but here we use the symmetry and the radial part: $$\la x|\psi\ra = \psi(\vec{x})=R(r)Y_l^m(\hat{x}).$$

Now $\mom=\frac{\hbar}{i}\vec{\nabla}$, and in spherical coordinates $\vec{\nabla}=\hat{r}\ptl_r+\frac{\hat{\theta}}{r}{\ptl_\theta}+\frac{\hat{\phi}}{r\sin\theta}\ptl_\phi.$ Or we can express it more succinctly: $$\momv = \hat{r}\mom_r+(\hat{r}\times \mom)\times \hat{r}\implies \mom^2 = \mom_r^2+\frac{L^2}{r^2},$$ where the first term is the radial part and the second is the orbital/transverse part. Squaring yields the result given. We see that $$\mom^2=-\hbar^2(\ptl_r^2+\frac{2}{r}\ptl_r)+L^2/r^2\implies\left[\frac{-\hbar^2}{2m}\left(\ptl_r^2+\frac{2}{r}\ptl_r\right)+\frac{\hbar^2l(l+1)}{2mr^2}-\frac{e^2}{r}\right]R(r)=ER(r).$$

To solve, we begin by identifying the scale of the problem. We only want to write this equation in terms of length, where after multiplying through by $-2m/\hbar^2$ and defining $-2mE/\hbar^2=1/r_o^2$ and scaling by $r\to r/r_o=r$ we find $$\left[\left(\ptl_r^2+\frac{2}{r}\ptl_r\right) - \frac{l(l+1)}{r^2}+\frac{K}{r}\right]R=R,$$ where $$K=\frac{2me^2r_o^2}{\hbar^2}=\frac{e^2/r_o}{\hbar^2/(2mr_o^2)}$$ can be seen as the ratio of Coulomb energy in the atom to the kinetic energy at the typical length scale.

So we've identified two parameters: $K$, the Coulomb factor, and $E=-\hbar/2mr_o$ the binding energy, which depends on the length scale of the atom $r_o$. The physics is tied up in the Coulomb factor, and the rest becomes a math problem: $$R'' + \frac{2}{r}R'-\frac{l(l+1)}{r^2}R+\left(\frac{k}{r}-1\right)R=0.$$ This is an eigenvalue differential equation now, and we examine the solution near certain points.

Near $r\approx 0$, we substitute $R=r^{\alpha}$ and solve for the allowable powers as $r\to 0$. We need it to die quickly as it approaches the origin for normalizability, and we consider only the leading powers that might be degenerate (for $\alpha>0$). Thus $$\alpha(\alpha-1)=l(l+1)\implies \alpha=l, \alpha=-(l+1)\to R(r)=r^l+\frac{1}{r^{l+1}}.$$ The $r^l$ term is regular at the origin, and for $l\neq 0$ we can discard the second due to normalizability constraints: $$\int r^2 dr r^{-2(l+1)}<\infty.$$ But for $l=0$, the situation is less clear because the $r^2$ factors cancel out. This would still not be normalizable, as a constant will not integrate to less than infinity, but also we look at the probability current (derivatives of $\psi$). The current flow determines Hermiticity, and integration by parts during this would lead to a term $1/r^3$ which would not integrate to a noninfinite value, so we can discard the term for $l=0$ as well.

As $r\to\infty$, we have $R''=R$, which yields exponential functions but in order for it to die off we choose the negative. Thus we have found $$R(r)=r^le^{-r}\phi(r),$$ where $\phi(r)$ is some intermediate joining function. Plugging this form of $R(r)$ into the differential equation now will yield $$r\phi'' +\phi'\left[2(l+1)-2r\right]+\phi\left[-2(l+1)+K\right]=0,$$ and we seek power series solutions such that $\phi(r)=\sum_ka_kr^k.$ We insert the series and shift coefficient indices to find the recursion relation $$\frac{a_{k+1}}{a_k}=-\frac{K-2(l+k+1)}{(k+1)(k+2(l+1))}.$$

We have yet to find the energy, as it's still a part of the solution wrapped up in $K$. But we can consider the asymptotic forms of the series, that is $k\to\infty$. In such a limit $$\frac{a_{k+1}}{a_k}\approx \frac{2k}{k^2}=\frac{2}{k}\implies a_k\approx \frac{2^k}{2!}.$$ But this, now, multiplying $r^k$ in the power series form yields $\phi(r)=e^{2r}$, which would dominate over the exponential we have to kill the function at infinity. Thus, to retain normalizability, the only physical solution is if the series of $\phi(r)$ truncates. So there exists a $k_{max}$ such that $$K=2(l+k_{max}+1).$$ That is, $$E_{l,k_{max}}=\frac{-me^4}{2\hbar^2}\frac{1}{(l+k_{max}+1)^2}.$$ We see from this that the value of $k_{max}$ is related to the radial quantum number, and the energy number $n$ is itself related to the sum of both the orbital number and the radial. This leads to an accidental degeneracy, since pairs of numbers can add up to the same value.

We see for the ground state, where $l=0$ and $k_{max}=0$ that $\psi_{00}(\vec{x})=Ae^{-r/r_o}\cdot Y_0^0(\pos).$ Analogously, $$\psi_{10}(\vec{x})=Ae^{-r/r_o}\left[1+\frac{a_1}{a_0}r\right]Y_0^0(\hat{x}).$$ Note: we can recognize the Bohr solution by identifying the denominator proportional to the quantum number sum as $n^2$.

\subsection{Perturbation Theory}

We will first discuss time-independent, stationary perturbation problems, then stationary time-dependent, then scattering later in the semester.

\subsection{Time-Independent Stationary Perturbation}

The problem is as follows: we have a Hamiltonian $\Ham=H_o+V$, where we know the solutions and problem of $H_o$ but not necessarily of $V$. If $V$ is small, we are able to proceed with the theory but if not this is a useless method. I.e., if $\Ham=H_0+\lambda V$ for $\lambda \ll 1$ then we can do so. Normally, we don't have such a case so we must organize and justifying our procedure more carefully.

We have $$\Ham|\psi\ra = E|\psi\ra,$$ where we assume $|\psi\ra = |\psi_0\ra +|\psi_1\ra +|\psi_2\ra +\dots$ and $E=E_0+E_1+E_2+\dots$, where the indices correspond to progressively smaller corrections to the first order term. We consider $H_0$ to be zeroth order and $V$ to be first order, and we expand and multiply and group by order: $$H_0|\psi_0\ra = E_0|\psi_0\ra,\ \ \ \ H_0|\psi_1\ra + V|\psi_0\ra = E_0|\psi_1\ra + E_1|\psi_0\ra,$$ and so on.


\section{Day 9: 2/20}


\subsection{Perturbation Theory}

We consider time-independent, stationary state perturbation theory.

As last time, we try to solve $\Ham|\psi\ra=E|\psi\ra,$ which $\Ham=\Ham_o+V$. We again group by order after an expansion in perturbation correction orders: \begin{align*}
H_0|\psi_0\ra &= E_0|\psi_0\ra\\
H_0|\psi_1\ra + V|\psi_0\ra &= E_0|\psi_1\ra +E_1|\psi_0\ra\\
H_0|\psi_2\ra + V|\psi_1\ra &= E_0|\psi_2\ra + E_1|\psi_1\ra +E_2|\psi_2\ra
\end{align*}

NOTE: All subscripts here indicate only the order of the perturbation -- i.e., $|\psi_0\ra$ has quantum numbers relating to the energy: $|\psi_{0n}\ra$. We set the condition that $\la \psi_1|\psi_0\ra=0$ (i.e. orthogonality), or else we could separate the shared component from $|\psi_1\ra$ and allocate it to $|\psi_0\ra$ anyway. With this condition, we take the inner product of the second equation with $\la \psi_0|$ to find $$E_1=\la\psi_0|V|\psi_0\ra.$$ Now, knowing $E_1$ we  can solve for $|\psi_1\ra$ in the same equation. This leads to a formal matrix equation $$(E_0-\Ham_o)|\psi_1\ra = \left[\Id - |\psi_0\ra\la \psi_0|\right]V||\psi_0\ra= QV \to |\psi_1\ra = \frac{Q}{E_0-\Ham_o}V|\psi_0\ra,$$ where the final equality is reached by taking the matrix inverse of $E_0-\Ham_o$. We note $Q^2=Q$, so this is a projector that projects onto the entire space minus the state we're considering. We assume the state are nondegenerate for this scenario, so that when applying the operator there are no divisions by zero. Note: since $|\psi_0\ra$ has been removed from the space, $[Q,\Ham_o]=0$ so we can rewrite this as $$|\psi_1\ra = Q\frac{1}{E_0-\Ham_o}QV|\psi_0\ra.$$

For the second order term, we again project the equation onto $|\psi_0\ra$ with the same orthogonality condition to find $$E_2=\la\psi_0|V|\psi_1\ra = \la \psi_0|V\frac{Q}{E_0-\Ham_o}V|\psi_0\ra.$$ We then use this to find $|\psi_2\ra$ to be $$|\psi_2\ra = QV\frac{Q}{E_0-\Ham_o}V|\psi_0\ra - \frac{Q}{E-\Ham_0}V(\Id-Q)V|\psi_0\ra.$$

Under what condition is this organization of the answer useful? $$E=E_o+\la V\ra_0 + \la V\frac{Q}{E-\Ham_o}V\ra_0$$

If the expectation values above with respect to the unperturbed basis holds $E_0>E_1>E_2$ then it's justified, or if $V$ is characterized by some parameter $\lambda\ll1$. In that case, successive matrix power $V_{nm}$ get smaller and smaller. This is also only valid if the $E_n-E_m$ is never zero (i.e., nondegenerate).

We note that $$E_n-E_{n0}=\la\psi_{n0}|V|\psi_{n0}\ra + \sum_{m\neq n} \frac{|\la \psi_{n0}|V|\psi_{m0}\ra|^2}{E_{n0}-E_{m0}}.$$ The first correction just shifts the energy value by the diagonal $V$ entries for a given level. It's important to note, though, that the second term (when $n=0$ and for $m>n$) \textbf{always lowers the ground state energy.}

For a degenerate perturbation, we could have some sublevel $|n\ra$ that is $\Delta$-degenerate, classified by substates $|n\Delta\ra$. In this case, we first diagonalize $V$ in the degenerate subspace first by defining $|\tilde{ni}\ra=\sum_{j=1}^\Delta C_{ij}|nj\ra$ such that $V|\tilde{ni}\ra = E_{ni}|\tilde{ni}\ra.$ In this space, the matrix for $V$ would be $\Delta\times\Delta$ in size. If more than one state is degenerate, we repeat the process for each subspace then proceed as above in the nondegenerate case, using the states $\{|j\notin \Delta\ra, |\tilde{ni}, i\in\Delta\ra\}$. If such a linear combination doesn't exist for all the substates, then the process can't be applied to everything and we will lose information.

\subsubsection{Quadratic Stark Effect}

We consider $\vec{E}=E\hat{z}$ applied to a hydrogen atom. With the positive center and the negative charge distribution around it, the electric field couples to the dipole moment giving $V=-\vec{p}\cdot\vec{E}$. Here we have $$\Ham=\Ham_o+V, \ \ \ \Ham_o=\frac{p^2}{2m}-\frac{e^2}{r}.$$

We note that $E_n\propto n^{-2}$, so only $E_0$ for $k=l=0$ and $n=1$ (given that $n=k+l+1$ from the Coulomb solution) is nondegenerate. The ground state is $$\psi_{00}=\frac{C}{\sqrt{4\pi}}e^{-r/a}$$ where $a$ is the Bohr radius. We note that this ground state wavefunction has even parity, since we saw the parity depends on $(-1)^l$ and $l=0$ here. So $$E_{01}=\la\psi_{00}|-eE\hat{z}|\psi_{00}\ra=\la \psi_{00}| \pi \pi(-eE\hat{z})|\psi_{00}\ra = -E_{01},$$ so we see that $E_{01}=0$ (since operators with odd parity have no expectation value under even parity states).

Now, $$E_{02}=(eE)^2\sum_{n\neq 0} \frac{|\la\psi_{00}|\hat{z}|\psi_{n0}\ra|^2}{E_{00}-E_{n0}}.$$ We note that this is quadratic in $E$, hence the name. Now we note that $\nabla^2\frac{\hat{z}^3}{3!}=z$, so for some reason we substitute in $\frac{-2m}{\hbar^2}[\Ham_o,z^3/3!]$ into the first term which pulls out a term $E_{00}-E_{0n}$ to cancel in the denominator leaving us with (after using the identity for completeness) $$E_{02}=-\frac{1}{2}\alpha_E E^2\to \alpha_E=(-2e^2)\frac{-2m}{\hbar^23!}\la\psi_{00}|z^4|\psi_{00}\ra$$

\section{Day 10: 2/22}
\subsection{Linear Stark Effect}

We now consider the same setup as yesterday, but with an excited state. Noting that $n=k+l+1$, we have two degenerate states for $n=2$: $(k,l)=(1,0)$ or $(0,1)$. We use spectroscopic notation to differentiate between the two: $nL_J$, where $n$ is the principal energy level, $L$ is the magnitude of $l$, and $J$ is the magnitude of the vector sum $\vec{L}+\vec{S}$. Note, here we consider an electron with $s=\frac{1}{2}$. For example, in the ground state the only energy level is $1S_{1/2}$. But for $n=2$, we have $$2S_{1/2}, \ \ 2P_{1/2}, \ \ 2P_{3/2}.$$ We also note that technically, $1S_{1/2}$ has two-fold degeneracy for the energy, since spin up or down plays no part. But we also note that the Hamiltonian considered doesn't see spin, since the dipole term ignores it. So we can effectively factorize the state such that the spin makes no difference. In so doing, we remove the $n=2$ degeneracies relating to spin going from 8-fold degeneracy to just 4-fold degeneracy.

We want to know the effect of the dipole term on the second energy shell, which requires degenerate perturbation theory. We note that the degeneracy is 4, so the matrix in this subspace will be a $4\times 4$ matrix. We have two choices as well: we could use the $|lm\ra\otimes|sm_j\ra$ product basis or the recoupled $|lsjm\ra$ basis. Since the spin factorizes out, all we need is the first one since the analysis will be simpler. 

We now consider the symmetries. We note that $V$ under parity transformation is odd: $\pi V\pi^{-1}=-V$, due to the $\hat{z}$ term in it. We also note that $\hat{z}=r\cos\theta$, so now $[L^2,V]\neq 0$ due to theta derivatives in the spherical harmonics. This breaks overall rotational symmetry, but we note that $[L_z,V]=0$ still, so some symmetry remains. These symmetries lead to selection rules.

In our chosen basis $|lm\ra$, we have diagonalized rotations (which is good, since there is some rotational symmetry in our problem). Thus $$L^2|lm\ra = \hbar^2l(l+1)|lm\ra, L_z|lm\ra = \hbar m|lm\ra, \pi|lm\ra = (-1)^l|lm\ra.$$

Our space is spanned by the kets $\{|nlm\ra\}=|200\ra, |211\ra, |210\ra, |21-1\ra$. We wish to find matrix elements for $\la n'l'm'|V|nlm\ra$. We note that since $[L_z,V]=0$ that $m=m'$ must be enforced. Under parity, the sign is flipped so we also can't connect the same states $l$ with themselves. That is, by insertion: $$\la n'l'm'|\pi^{-1}\pi V \pi^{-1}\pi|nlm\ra = (-1)^{l'+l+1}\la n'l'm'|V|nlm\ra,$$ so it must be that $l+l'+1$ is even for nonzero entries. Since $V\sim z\sim r\cos\theta \sim Y_1^0$, the addition of angular momentum rules thus enforce $$\la n'l'm'|V|nlm\ra = \delta_{mm'}\delta_{l', l\pm 1}\cdot C,$$ for some number $C$. Thus the only connected terms are $\la 200|V|210\ra = \Delta$, and hermiticity enforces the transpose is $\Delta$ as well. This will effectively be a block matrix if we reshuffle, and diagonalizing the matrix yields $\lambda=\pm \Delta$ with $$+\Delta: |\tilde{210}\ra = \frac{1}{\sqrt{2}}\left[|200\ra+|210\ra\right], \ \ \ -\Delta: |\tilde{200}\ra = \frac{1}{\sqrt{2}}\left[|200\ra - |210\ra\right].$$ So we've split the degeneracy in two states, although the remaining states are still degenerate as they were before.

We have everything we need to calculate $\Delta$: $$\Delta = \la 210|eE\hat{z}|200\ra = (eE)\int d^2r\Omega \psi_{210}^*(\vec{r})r\cos\theta \psi_{200}(\vec{r})\propto eEa\cdot C,$$ thus since this energy shift is linear in $E$ it is the linear Stark shift.

\subsection{Spin-Orbit Coupling}

Again we have a hydrogen atom, with $$\Ham_0=\frac{p^2}{2m}-\frac{e^2}{r}.$$ We know this has accidental degeneracy since the eigenstates don't see orbital angular momentum: $\Ham_0|nlm\ra = E_n|nlm\ra$. But the electron actually has spin $\vec{S}$. The proton does as well. In the frame where the proton is stationary, the electron feels an applied electric field but no magnetic field. In the electron's rest frame, however, the proton seems to be rotating around it thus producing a magnetic field on it associated to the proton's current. Lorentz boosting from the first to the second gives $$\vec{E}'=\vec{E}+\vec{\beta}\times\vec{B}, \ \ \ \vec{B}'=\vec{B}-\vec{\beta}\times\vec{E}$$ where the unprimed $\vec{B}=0$. Now the Hamiltonian $\Ham=\Ham_0-\vec{\mu}\cdot\vec{B}$. $$V=-\vec{\mu}\cdot\vec{B}=-\frac{g_ee}{2mc}\vec{S}\cdot(\vec{\beta}\times\vec{E})= \frac{-e}{mc^2}\vec{S}\cdot (\vec{v}\times \nabla\phi)=-\frac{e}{mc^2}\vec{S}\cdot(\vec{v}\times \vec{r}\frac{\phi'}{r}).$$ This simplifies to $$V=\frac{e}{(mc)^2}\frac{\phi'}{r}\vec{S}\cdot\vec{L}.$$ We note that the boosted frame isn't inertial due to the electron's proper rotating motion, but doing the calculation with this in mind from the Dirac equation yield $$V=\frac{1}{2}\left[\frac{e}{(mc)^2}\cdot\frac{\phi'}{r}\right]\vec{S}\cdot\vec{L}.$$ Estimating the energy yields something on the order of $\alpha^2\cdot E_R$, where $E_R=\frac{e^2}{a}$ is the Rydberg energy. This lifts the accidental degeneracy in the atom, and can be treated with perturbation theory: $$\Ham=\Ham_0+\phi(r)\vec{S}\cdot\vec{L},$$ where $\phi(r)$ is not the same as the potential as in the $V$. The spin-orbit coupling introduces fine splitting of the energy levels in hydrogenic atoms. We note that $$[J^2,\vec{S}\cdot\vec{L}]=[L^2,\vec{S}\cdot\vec{L}]=[J_z,\vec{S}\cdot\vec{L}]=[S^2,\vec{S}\cdot\vec{L}]=0$$ while neither $L_z$ or $S_z$ commute. So the correct basis here is $|lsjm\ra$. We note now that $$\la n l s j'm'|V|nlsjm\ra = C\cdot\delta_{jj'}\delta_{mm'}\delta_{ll'}\delta_{ss'}$$ so $V$ is diagonal in this basis. Noting that $$J=\vec{S}+\vec{L}, J^2=L^2+S^2+2\vec{S}\cdot\vec{L}$$ leads us to find $$\la nlsjm|\vec{S}\cdot\vec{L}|nlsjm\ra = \la n|\phi(r)|n\ra\cdot\frac{1}{2}\hbar^2[j(j+1)-l(l+1)-3/4].$$


\section{Day 11: 2/27}
The midterm is next Thursday, although he would've made it on Tuesday the same day the homework is due if someone hadn't questioned him about it. The midterm covers everything including perturbation theory, which he will likely finish within the week.

\subsection{Spin-Orbit Coupling}

We recall that the hydrogen atom is highly (and accidentally) degenerate, with the energy quantum number being a sum of radial and angular quantum numbers. This will be similar to first order for any alkali atom, with leading solutions just being the Coulomb ones.

We recall the setup: a heavy positive center (approximately fixed) and a rotating single electron in the outer shell with charge $e$, mass $m_e$, and spin $\vec{S}$. Boosting to the electron's rest frame, we see a magnetic field induced on it by the proton's rotation (although suppressed by a factor of $1/c$). The Lorentz transformations between frames: $$\vec{E}'=\vec{E}+\vec{\beta}\times\vec{B}, \ \ \ \vec{B}'=\vec{B}-\vec{\beta}\times\vec{E}, \ \ \ \vec{\beta}=\frac{\vec{v}}{c}.$$ Recalling the potential associated with a magnetic field, $$V_{so}=-\vec{\mu}_e\cdot\vec{B}=-\left(\frac{g_ee}{2m_ec}\right)\vec{S}\cdot\left(-\frac{\vec{v}}{c}\times\vec{E}\right).$$ We can write $E=-\nabla\phi$, and if $\phi$ is radial we have $\nabla\phi=\hat{r}\phi'$. Multiplying by $m_e$ gives $\vec{p}$ and we find that $$V_{so}=\frac{e}{(m_ec)^2}\left(\frac{\phi'}{r}\right)\vec{S}\cdot\vec{L}.$$ The inclusion of $L$ now lifts the degeneracy we had before. We can estimate the magnitude of this correction, noting thta $\frac{\hbar^2}{m_ea}=e^2$ so that the dimensions of $V$ are given by $$[V]=\left(\frac{e}{mc}\right)^2\frac{\hbar^2}{a^3}=\left(\frac{\hbar}{mca}\right)^2\frac{e^2}{a}=\left(\frac{e^2}{\hbar c}\right)^2\frac{e^2}{a}=\alpha^2\frac{e^2}{a}.$$ So the correction will be on the order of $\alpha^2\sim 10^{-4}$ times the usual Rydberg energy.

Now $\Ham=\Ham_o+V_{so}$, and we note the $\phi'=\frac{e\phi'_c}{r}\approx \frac{ee^{-\mu r}}{r}$ for atoms besides hydrogen, taking into account the charge screening from the inner shells with $\mu$ being a screening length. But in hydrogen, this is just $1/r$ as we have learned.

So $$V_{so}=\left[\frac{e^2}{(mc)^2}\frac{\phi_c'}{r}\right]\vec{S}\cdot\vec{L}\equiv \phi(r)\vec{S}\cdot\vec{L},$$ where the final $\phi(r)$ is not the same as the potential $\phi$ in brackets.

So $$\Ham=\left[\frac{\momv^2}{2m}-\frac{e^2}{r}\right]+V_{so},$$ which we can model as a perturbation. We note that $$[\{J^2,J_z,L^2, S^2\}, \vec{S}\cdot\vec{L}]=0,$$ so we choose to work in the $|lsjm\ra$ basis (or more concretely the $|n\ra\otimes|lsjm\ra$ basis, but the radial $n$ term factorizes). Noting that $$\vec{J}=\vec{S}+\vec{L}\implies 2\vec{S}\cdot\vec{L}=J^2-L^2-S^2,$$ we find $$\la n'l's'j'm'|V_{so}|nlsjm\ra = \la n'|\phi(r)|n\ra\la l's'j'm'|\vec{S}\cdot\vec{L}|lsjm\ra.$$ The $\phi(r)$ function will be radially symmetric, so rotationally symmetric as well and thus won't change the radial quantum number.  So we end up with $$\la n'l's'j'm'|V_{so}|nlsjm\ra = \delta_{nn'}\phi_n(r)\delta_{ll'}\delta_{ss'}\delta_{jj'}\delta_{mm'}\cdot \frac{\hbar^2}{2}\left[j(j+1)-l(l+1)-\frac{3}{4}\right].$$

We can rewrite this in the spectroscopic $nL_J$ "basis" or form, noting that when $J=l+\frac{1}{2}$ that the bracketed term simplifies to $\frac{\hbar^2}{2}l$, and with $J=l-\frac{1}{2}$ we get $-\frac{\hbar^2}{2}(l+1)$. So the $nS_{1/2}$ states do not get any change in energy, while for example the $2P_{1/2}$ state gets lowered in energy while the $2P_{3/2}$ state gets raised in energy. This is seen empirically in sodium lamp light.

\subsection{Zeeman Effect}

We now want to consider what happens if the electric is subject to a static external magnetic field, as opposed to the original external electric field caused by the proton. We recall that the quantum problem is not sensitive to $\vec{B}$, but instead to the vector potential $\vec{A}$, and such a choice of the potential is arbitrary given the gauge invariance. But since the original problem without including the magnetic field is rotationally symmetric, we choose a potential that is also spherically symmetric (i.e., symmetric with respect to both $x$ and $y$) that results in $\vec{B}=B\hat{z}$. One such choice is $$\vec{A}=\left(-\frac{By}{2},\frac{Bx}{2}, 0\right).$$ One can check that $\nabla\times\vec{A}=\vec{B}$. We now have a Hamiltonian $$\Ham=\frac{(\momv-e\vec{A}/c)^2}{2m}-\frac{e^2}{r}+V_{so}.$$ We expand this out to find $$\Ham=\frac{\momv^2}{2m}-\frac{e}{2mc}(\momv\cdot\vec{A}+\vec{A}\cdot\momv)+\frac{e^2}{2mc^2}\vec{A}^2-\frac{e^2}{r}+V_{so}.$$ We note that $\momv\cdot\vec{A}=\frac{\hbar}{i}\nabla\cdot\vec{A}$, but we must remember that when acting on a wavefunction that the product rule will hold, so that $$\momv\cdot\vec{A}=\frac{\hbar}{i}\nabla\cdot\vec{A}+\vec{A}\cdot\momv=\vec{A}\cdot\momv,$$ since the vector potential must be divergenceless (and from the math it is anyway). This reduces the middle term into $$-\frac{e}{mc}\vec{A}\cdot\momv = -\frac{eB}{2mc}(-y\mom_x+x\mom_y)=-\frac{eB}{2mc}L_z.$$ The $A^2$ term reduces to a term proportional to $r_\perp^2$ (from the $x^2+y^2$ term), and we must add the energy associated with the electron's spin coupling to the external field: $$-\vec{\mu}_e\cdot\vec{B}_{ext}=\frac{-ge}{2mc}\vec{S}\cdot\vec{B}=\frac{-geB}{2mc}S_z.$$ This gives us a final Hamiltonian $$\Ham=\left[\frac{\momv^2}{2m_e}-\frac{e^2}{r}+V_{so}\right] -\frac{eB}{2m_ec}\left(L_z+g_eS_z\right)+\frac{e^2B^2}{8m_ec^2}r_\perp^2.$$ We want to know which of the new terms is dominant now, and compare to the spin-orbit coupling to see which can be treated on a perturbation on which.

The dimensions of the first term are $$[(1)]=\frac{eB\hbar}{m_ec}=\hbar\omega_c,$$ but we want to express in terms of the Rydberg energy to compare with everything else. So $$[(1)]=\frac{eB\hbar}{m_ec}\cdot\frac{a}{e^2}\frac{e^2}{a}= \frac{Ba^2}{\hbar c/e}\frac{e^2}{a}=\frac{\Phi_B}{\phi_o}\frac{e^2}{a},$$ where we've used again that $e^2=\hbar^2/(m_ea)$ in changing terms. We see that the energy now is on the order of the magnetic flux in units of quantum fluxes across the atom. A similar process for the final term yield that $$[(2)]=\left(\frac{\Phi_B}{\phi_o}\right)^2\frac{e^2}{a}.$$

This yields a Hamiltonian with contributions on the order of $$\Ham \to \frac{e^2}{a}\left[1+\alpha^2+\frac{\Phi_B}{\phi_o}+\left(\frac{\Phi_B}{\phi_o}\right)^2\right].$$ So the flux contributions will determine whether we can treat these terms as perturbations or not. That is, with small $B$ the flux terms are much less than $\alpha^2$ (the Zeeman regime) or greater than $\alpha^2$ (the Paschen-Bach regime).

\subsection{The Weak-Field Limit}

We assume $\frac{\Phi_B}{\phi_o}\ll \alpha^2$, so we can even ignore the next term that is a squared contribution. We rewrite the Hamiltonian now as $$\Ham=\Ham_o+V_{so}-\frac{\omega_c}{2}(L_z+gS_z).$$ What is the best basis now? Since $J^2$ and $J_z$ both commute with $L_z$ and $S_z$, then those are good quantum numbers. $S^2$ and $L^2$ also commute with both, so we stay in the $|lsjm\ra$ basis. We are concerned with the matrix elements $$\la l's'j'm'|-\frac{\omega_c}{2}(L_z+gS_z)|lsjm\ra = -\frac{\omega_c}{2}\la l's'j'm'|J_z+(g-1)S_z|lsjm\ra,$$ where we've used $J_z=L_z+S_z$. But these are eigenstates of $J_z$, so this reduces even further to $$-\frac{\omega_c}{2}\left[m\hbar + \la lsjm|(g-1)S_z|lsjm\ra\right],$$ where we've used the fact that $S_z$ doesn't change the quantum numbers to show it's diagonal. Setting $g_e\approx 2$ we continue. We note that $S_z$ has vector content (i.e. it's $S^1_0$ in the spherical tensor operator basis), and tensor operators in the recoupled basis are related to Clebsch coefficients and irreducible matrix elements. So to evaluate this matrix element, we'll use the Wigner-Eckart theorem: $$\la \alpha'j'm'|T_q^k|\alpha jm\ra = \frac{\la kjj'm'|kjqm\ra}{\sqrt{2j+1}}\la \alpha'j'||T^k||\alpha j\ra,$$ where we form $\vec{J}'=\vec{k}+\vec{J}$. Now, both $S_z$ and $J_z$ are tensors of rank one with $q=0$. So $$\la j'm'|S_{m=0}^1|jm\ra = [C]\la j'||S^1||j\ra$$ and the same for $J_z$.

Now we consider $$\frac{\la j'm'|\vec{S}\cdot\vec{J}|jm\ra}{\la j'm'|\vec{J}\cdot\vec{J}|jm\ra},$$ which we think of as the projection of $\vec{S}$ onto $\vec{J}$ normalized by $j$. By the Wigner-Eckart theorem (?????) this has the same ratio as $$\frac{\la j'm'|S_z|jm\ra}{\la j'm'|J_z|jm\ra},$$ so we write the energy matrix element as $$-\frac{\omega_c}{2}\left[m\hbar + \la lsjm|J_z|lsjm\ra \cdot \frac{\la lsjm|\vec{S}\cdot\vec{J}|lsjm\ra}{\la lsjm|J^2|lsjm\ra}\right].$$ We can rewrite the dot product similarly to how we did before, and we find that the Zeeman matrix element is $$-\frac{\omega_c}{2}m\hbar\left[1+\frac{1}{2}\frac{j(j+1)-l(l+1)+\frac{3}{4}}{j(j+1)}\right]$$ Now, going back to the spectroscopic basis, we have $nL_J$. For $J=l+\frac{1}{2}$, the fraction on the right ends up being $\frac{1}{l+1/2}$. For $J=l-\frac{1}{2}$, the fraction yields $\frac{-1}{l+1/2}$. Thus here, we have $$-\frac{\omega_c}{2}m\hbar\left[1\pm \frac{1}{2l+1}\right].$$ So the states split once more, lifting degeneracy in the projection quantum number.


\section{Day 12: 3/1}

\subsection{Paschen-Back Effect}

We continue with the magnetic interactions, except this time we assume that $\frac{\Phi_B}{\phi_o}\gg \alpha^2$ so that we have $$\Ham = \left[\frac{p^2}{2m}-\frac{e^2}{r}-\frac{\omega_c}{2}(L_z+g_eS_z)\right]+\phi(r)\vec{S}\cdot\vec{L} = H_o+V.$$ Now the natural basis would be the one in which we utilize the quantum numbers $m_l$ and $m_s$, so we use the split basis $|lm_lsm_s\ra = |lm_l\ra\otimes |sm_s\ra$. We're only interested in the angular part again, and we see immediately that $H_o$ is diagonal in this basis, so $$\la lm_lsm_s|L_z+gS_z|lm_lsm_s\ra = \hbar(m_l+g_em_s)\delta_{ll'}\delta_{m_lm_l'}\delta_{ss'}\delta_{m_sm_s'}.$$ Now we take $g_e=2$, and we in fact see that there is some degeneracy since $$(m_l+2)+2\frac{-1}{2}= m_l+2\frac{1}{2}.$$ So we see the states $|m_l+2, -1/2\ra$ and $|m_l, 1/2\ra$ are degenerate with each other within the same shell. We will see the hyperfine perturbation lift the degeneracy, but we will have to account for this degeneracy when perturbing. In particular, we see the $|1,-1;1/2,1/2\ra$ has $0$ from this, and does the $|1,1;1/2,-1/2\ra$ state, and since they are within the same $l=1$ shell they are degenerate. However, the the states with the same energy from $l=0$ and $l=1$ are not linked (for some reason).

\subsection{Time Dependent Perturbation Theory}

In general, we will have $\Ham=H_o+V(t)$. Considering the Schrodinger equation, we know how to organize $H_o|n\ra=E_n|n\ra$. Applying the time evolution operator gives $|n(t)\ra = e^{-iE_nt/\hbar}|n(0)\ra.$ We can construct an arbitrary state now as $$|\alpha(t)\ra = \sum_n c_n(t)|n(0)\ra = \sum_n c_n(0)e^{-iE_nt/\hbar}|n(0)\ra.$$ When $V\neq 0$, we have $$(H_o+V(t))|\alpha(t)\ra = i\hbar\ptl_t|\alpha(t)\ra.$$ This can be solved by including additional time dependence once again in the $c_n(t)$ as opposed to $c_n(0)$. So we get the equation, after application and cancellation of terms $$\sum_n i\hbar \dot{c}_n(t)e^{-iE_nt/\hbar}|n(0)\ra = \sum_n V(t)c_n(t)e^{-iE_nt/\hbar}|n(0)\ra.$$ We can now project to find a given coefficient: $$i\hbar \dot{c}_n = \sum_m \la n|V(t)|m\ra e^{-i(E_m-E_n)t/\hbar}c_m(t).$$ We see that the time dependent potential mixes up different states, and allows the coupling to transition between states $n$ to $m$. For most cases, this can't be solved exactly and must be treated perturbatively. However, we solve an exact case using the spin-1/2 problem (which can be mapped onto from any 2 state system, since the Pauli matrices are complete). 

\subsubsection{Spin-1/2 Exact Solution}

We suppose we have $$H=H_o+V(t)=\left(\begin{matrix}
E_1 & 0 \\ 0 & E_2
\end{matrix}\right)+\left(\begin{matrix}
0 & \gamma e^{i\omega t} \\ \gamma e^{-i\omega t} & 0
\end{matrix}\right).$$ We assume complete diagonality for $H_o$ and off-diagonality for $V$, since if there were diagonal components we could just absorb them into $H_o$. We also assume the harmonic form of $V(t)$ because any function of time can be decomposed into its harmonic Fourier modes. With a two state system, then, the problem becomes $$i\hbar\left(\begin{matrix}
\dot{c}_1\\\dot{c}_2
\end{matrix}\right) =\left(\begin{matrix}
0 & \gamma e^{i\omega t} \\ \gamma e^{-i\omega t} & 0
\end{matrix}\right) \left(\begin{matrix}
c_1e^{-iE_{12}t/\hbar}\\c_2e^{-iE_{21}t/\hbar}
\end{matrix}\right), \ \ \ E_{ij}=E_i-E_j=\hbar\omega_{ij}; \ \ \tilde{\omega}=\omega-\omega_{21} $$
With the above definitions, the problem becomes $$ i\hbar\left(\begin{matrix}
\dot{c}_1\\\dot{c}_2
\end{matrix}\right) =\gamma \left(\begin{matrix}
c_2e^{i\tilde{\omega}t/\hbar}\\c_1e^{-i\tilde{\omega}t/\hbar}
\end{matrix}\right) $$ and we now redefine our variables again to have $\tilde{c}_{2/1}=c_{2/1}e^{\pm i \tilde{\omega}t/\hbar}$. We have now $$\left(\begin{matrix}
\dot{\tilde{c}}_1\\\dot{\tilde{c}}_2
\end{matrix}\right)=\left(\begin{matrix}
\hbar\tilde{\omega}/2 & \gamma \\ \gamma & -\hbar\tilde{\omega}/2
\end{matrix}\right)\left(\begin{matrix}
\tilde{c}_1\\\tilde{c}_2
\end{matrix}\right)\to \left(\begin{matrix}
\tilde{c}_1\\\tilde{c}_2
\end{matrix}\right) = Ae^{-i\lambda_1t/\hbar} \left(\begin{matrix}
a_1\\ b_1
\end{matrix}\right) + Be^{-i\lambda_2t/\hbar}\left(\begin{matrix}
a_2\\ b_2
\end{matrix}\right) .$$ We now plug back in for the original coefficients to get $$\left(\begin{matrix}
c_1\\ c_2
\end{matrix}\right) = Ae^{-i\lambda_1t/\hbar} \left(\begin{matrix}
a_1e^{i\tilde{\omega}t/\hbar}\\ b_1e^{-i\tilde{\omega}t/\hbar}
\end{matrix}\right) + Be^{-i\lambda_2t/\hbar}\left(\begin{matrix}
a_2e^{i\tilde{\omega}t/\hbar}\\ b_2e^{-i\tilde{\omega}t/\hbar}
\end{matrix}\right). $$ We say that at $t=0$, the particle was initially at $E_1$ so $c_1(t=0)=1$ and $c_2(t=0)=0$. This gives $$Aa_1+Ba_2=1, \ \ \ Ab_1+Bb_2=0.$$ We see that $$c_2(t)=Ab_1\exp\left[-i(\lambda_1+\frac{\hbar\tilde{\omega}}{2})t\right]+Bb_2\exp\left[i(\lambda_2+\frac{\hbar\tilde{\omega}}{2})t\right]$$ which then implies $$|c_2(t)|^2=|Ab_1|^24\sin^2(\lambda_{12}t/2).$$ Finding the eigenvalues yields $$\lambda_{1,2}=\pm\sqrt{\gamma^2+\hbar^2\tilde{\omega}^2/4},$$ and finding the eigenvector components gives us a final results $$|c_2(t)|^2=\frac{\gamma^2}{\left(\frac{\hbar\tilde{\omega}}{2}\right)^2+\gamma^2}\sin^2\left[\sqrt{\left(\frac{\hbar\tilde{\omega}^2}{2}\right)^2+\gamma^2}t\right].$$ This is an oscillatory Lorentzian, with maximum amplitude when the difference $\tilde{\omega}=0$.


\section{Day 13: 5/6}

Written on Wednesday; class tomorrow was canceled so no test tomorrow unfortunately.

\subsection{Spin-1/2 Time-Dependent Perturbation}

As last time, we have a two level system with energies $E_1$ and $E_2$. (Any two level system can be mapped onto the spin-1/2 problem, since it's basis is complete.) We have a Hamiltonian of the form $$ H=H_o+V(t)=\left(\begin{matrix}
E_1 & 0 \\ 0 & E_2
\end{matrix}\right)+\left(\begin{matrix}
0 & \gamma e^{i\omega t} \\ \gamma e^{-i\omega t} & 0
\end{matrix}\right).$$ Our state in general is also $$|\alpha(t)\ra = c_1(t)e^{-iE_1t/\hbar}|1\ra+c_2(t)e^{-iE_2t/\hbar}|2\ra.$$ With the assumptions of last time, we have $c_1(0)=1$ and $c_2(0)=0$. We found Rabi's formula $$|c_2(t)|^2 = \frac{\gamma^2}{\left(\frac{\hbar\tilde{\omega}_{21}}{2}\right)^2+\gamma^2}\sin^2\left[\sqrt{\left(\frac{\hbar\tilde{\omega}_{21}}{2}\right)^2+\gamma^2}\frac{t}{\hbar}\right],$$ where $\tilde{\omega}_{21}=\omega - (E_2-E_1)/\hbar$. So the transition between the states has a resonance at the natural energy separation frequency. We will see that this is a relatively general phenomenon.

\subsection{Magnetic Resonance}

Suppose we have $B(t)=B_o\hat{z}+B_1(\cos\omega t \hat{x}+\sin\omega t \hat{y})$ and we have a spin-1/2 particle in the $|+\ra$ state. We assume here that $B_o\gg B_1$. Now the Hamiltonian $$\Ham=-\mu\cdot B=\frac{e\hbar}{2mc}\left[B_o\sigma_z+B_1(\sigma_x\cos\omega t+\sigma_y\sin\omega t)\right]=\frac{-\hbar\omega_c}{2}\left[\left(\begin{matrix}
1&0\\0&-1
\end{matrix}\right)+\frac{B_1}{B_o}\left(\begin{matrix}
0&e^{-i\omega t}\\e^{i\omega t}&0
\end{matrix}\right)\right].$$

\subsection{Masers}

Suppose we have a pyramidal NH$_3$ molecule. The Coulombic interaction is minimized when N is equidistant from the three hydrogens in the plane, but there are two possible locations for this minimum to occur: $z=\pm a$, for some distance $a$. This leads to a bimodal potential that is symmetric: i.e., it is even under parity. But this would lead to a degeneracy, so we construct $$|\pm\ra = \frac{1}{\sqrt{2}}\left[|L\ra \pm |R\ra\right]$$ that are eigenstates of the parity operator for the left and right equilibrium states: $\Pi|\pm\ra = \pm |\pm\ra$. There is a finite probability of tunneling in this scenario, so the symmetric/antisymmetric states split the energy on their own before perturbation.

Now, adding a time-dependent electric field $\vec{E}(t)=E\cos\omega t \hat{z}$. This gives a term in the Hamiltonian $$H(t)=-\vec{p}\cdot \vec{E}=-q\hat{z}E\cos\omega t$$. Thus $$\Ham=\Ham_o+V(t) = \left(\begin{matrix}
E_+&0\\0&E_-
\end{matrix}\right)+\frac{qE\hat{z}}{2}[e^{i\omega t}+e^{-i\omega t}],$$ where the second term is odd under parity. Therefore, the potential perturbation only connects even parity states to odd parity states and vice versa. So the potential matrix must be off-diagonal in this basis. This yields a form $$\Ham = \left(\begin{matrix}
E_+&0\\0&E_-
\end{matrix}\right)-\frac{qEz_\pm}{2}\left(\begin{matrix}
0&e^{i\omega t}\\e^{-i\omega t}&0
\end{matrix}\right) + \mathrm{a\ Hermitian\ conjugate.}$$ We note that the conjugate arises from the form $\la+|z|-\ra \cos\omega t$ being the off-diagonal terms, so we say these expectation values are just $z_\pm$.

\subsection{Formal Perturbation Theory}

The time-dependent Schrodinger equation $$i\hbar |\psi(t)\ra = [\Ham_o+V(t)]|\psi(t)\ra \to [i\hbar \ptl_t - \Ham_o]|\psi(t)\ra = V(t)|\psi(t)\ra$$ A clever substitution into the derivative side yields $$\left[e^{-i\Ham_o t/\hbar}i\hbar\ptl_t e^{i\Ham_o t/\hbar}\right]|\psi(t)\ra = V(t)|\psi(t)\ra \to i\hbar \ptl_t [e^{i\Ham_ot/\hbar}|\psi(t)\ra] = [e^{i\Ham_ot/\hbar}V(t)e^{-i\Ham_ot/\hbar}]e^{i\Ham_ot/\hbar}|\psi(t)\ra.$$ We relabel the "rotated" potential and transformed state as $|\psi(t)\ra_i$ and $V(t)_i$ to be the "interaction" representation potential and state. We note that this is a kind of in-between picture of the Schrodinger and Heisenberg picture (using the full Hamiltonian in $U(t)$), in that it splits the time-dependence among both the operators and the states as opposed to one or the other. But we note that this splitting is arbitrary now: some fraction can go into the operators and the rest into the states -- that is, this can be generalized into any intermediate representation varying from the Schrodinger to Heisenberg pictures.

Now, we have $$i\hbar\ptl_t|\psi(t)\ra_i = V_i(t)|\psi(t)\ra_i,$$ where at $t=0$ all pictures coincide with $|\psi(t=0)\ra_i\equiv |\psi(0)\ra.$ Since this is a first order equation, it can be formally integrated to find: $$|\psi(t)\ra_i = \bb{T}\exp\left[\frac{i}{\hbar}\int_0^t dt' V_i(t')\right]
|\psi(0)\ra.$$ Normally it would be an issue for $V_i(t)$ to depend on time, since it wouldn't commute with itself. That would lead to problems in order of integration upon successive expansion. That is, $$|\psi(t)\ra_i = \bb{T}\left[\Id - \frac{i}{\hbar}\int_0^t dt' V(t')-\frac{1}{2!\hbar^2}\int_0^t\int_0^t dt'dt'' V(t')V(t'')+\dots\right]|\psi(0)\ra.$$ But $\bb{T}$ tells you how to order things such that they are causal: $$\bb{T}(V(t'),V(t''))= \Theta(t'-t'')V(t')V(t'')+\Theta(t''-t')V(t'')V(t')$$ such that the largest time is on the left and smaller times are on the right, in a causal fashion. In this way, we could insert them above to find \begin{align*}\bb{T}\int_0^t\int_0^tdt'dt''V(t')V(t'') &= \int_0^tdt'\int_0^{t'}dt'' V(t')V(t'')+\int_0^tdt''\int_0^{t''}dt'V(t'')V(t')\\&=2\int_0^tdt''\int_0^{t''}dt'V(t'')V(t')\end{align*} after relabeling the integration variables. Now we have the perturbation ordered by powers of $V_i(t)$, so if small we can just approximate with the first order: \begin{mdframed} $$|\psi(t)\ra_{i,1}\approx \left[\Id - \frac{i}{\hbar}\int_0^t dt' V_i(t')\right]|\psi(0)\ra.$$ \end{mdframed}



\subsection{Fermi's Golden Rule}


Suppose we have a potential $V(t)=\Theta(t)\cdot V_o$ -- i.e., one that is turned on very suddenly by a switch then is constant afterwards. If the atom is in the ground state, what is the probability of finding it in state $|n\ra$? We denote the perturbed ground state with $|0(t)\ra_{i, 1}\equiv |0(t)\ra$. We are looking for $$\la n |0(t)\ra = -\frac{i}{\hbar}\int_0^t dt' \la n|V_i(t')|0\ra.$$ Now we note that $V_i$ is constant at and after $t=0$, so the matrix element comes out. We further note that this potential is \textbf{in the interaction picture}, so we have $$\la n |V_i(t')|0\ra = \la n | e^{i\Ham_ot/\hbar}V(t')e^{-i\Ham_ot/\hbar}|0\ra = \la n| e^{iE_nt/\hbar}V(t')e^{-iE_0t/\hbar}|0\ra.$$ We can now say that $$P_{0,n}(t)\simeq |\la n|0(t)\ra|^2 \equiv \frac{1}{\hbar^2}|\la n |V_o|0\ra|^2 \left|\int_0^t dt' e^{i\omega_{n0}t}\right|^2.$$ Carrying the integration out and squaring yields \begin{mdframed} $$P_{0,n}(t)\simeq \frac{|V_{n0}|^2}{E_{n0}^2} 4\sin^2\left[\frac{\omega_{n0}t}{2}\right] = \frac{t^2|V_{n0}|^2}{\hbar^2} \frac{\sin^2\left[\frac{\omega_{n0}t}{2}\right]}{\left(\frac{\omega_{n0}t}{2}\right)^2}.$$ \end{mdframed} This looks like an oscillatory graph enveloped by a $1/\omega^2$ curve at fixed $t$. The height of the central peak at a given time is on the order of $t^2$, while the width is of the order $1/t$. So we see that there is a band of states within the range that we could fall. The probability to migrate to a band of states, though is $$P_{0,n}(t)n(E_n)dE_n,$$ where $n(E_n)=dN/dE_n$ is the number density of states in that given interval $dE_n$. We note that $dE_n$ falls as $1/t$, and $P_{0,n}(t)$ goes as $t^2$ in the band. So combined together, this gives a probability proportional to $t$, which if divided by time gives the rate of transition.

\section{Day 14: Class Cancelled}

\section{Day 15: 3/20}

The test was moved to Thursday, and now possibly includes time-dependent perturbation theory.

\subsection{Sudden Interaction}

We consider a potential of the form $$V(t)=\Theta(t)\cdot V,$$ applied to a discrete spectrum. We want $|c_{in}(t)|^2$. We note that if the potential was time-independent, then energy would be conserved and no change in state would happen (since it can't suddenly increase energy).

Time-dependent perturbation theory gave us the result $$c_{in}(t)=\frac{-i}{\hbar}\int_{-\infty}^{\infty}dt \la n|V_i(t)|i\ra + O(V^2) = \frac{-i}{\hbar}\int_{-\infty}^{\infty} dt \la n | e^{i\Ham_ot/\hbar}V(t)e^{-i\Ham_ot/\hbar}|i\ra+O(V^2).$$ This simplifies to $$c_{in}(t)\simeq \frac{-i}{\hbar}V_{ni}\int_0^\infty e^{i\omega_{ni}t'} = \frac{-i}{\hbar}V_{ni}\frac{e^{i\omega_{ni}t}-1}{i\omega_{ni}},$$ where the integration is carried out by setting the upper limit to $t$ and considering the limit where $t\to\infty$. We note that $\omega_{ni}=(E_n-E_i)/\hbar.$

Now $$|c_{in}(t)|^2 = \frac{|V_{ni}|^2}{\hbar^2}\frac{\sin^2(\omega_{ni}t/2)}{(\omega_{ni}/2)^2} = \frac{|V_{ni}|^2}{\hbar^2}\frac{t^2\sin^2(\omega_{ni}t/2)}{(\omega_{nit}/2)^2}.$$ We note that this is a sinc function, with the first nodes at $x=\omega_{ni}t/2 = \pm \pi$. We solve for $\omega_{ni}$ to see $$\omega_{ni}=\frac{2\pi}{t},$$ which shoes that as $t\to\infty$ the principal peak of the sinc function narrows. Since most of the probability is carried by this peak, as $t$ increases it becomes more and more similar to a delta function: $$\lim\limits_{t\to\infty}\frac{\sin^2(\omega_{ni}t/2)}{(\omega_{nit}/2)^2} = \pi \delta(\omega_{ni}t/2) = \frac{2\pi}{t}\delta(\omega_{ni}),$$ where the $\pi$ factor is a normalization (since the area of the triangle is $\pi$) and the last equality is a property of delta functions. Now $$|c_{in}(t)|^2 = \frac{2\pi}{t}\frac{|V_{ni}|^2}{\hbar^2}\cdot t^2\delta(\omega_{ni}) \to W_{ni}\equiv \frac{|c_{in}(t)|}{t} = \frac{2\pi}{\hbar}|V_{ni}|^2\delta(E_{ni}),$$ where we use the delta function property again and take out the factor of $\hbar$. This shows that the rate of transition between states is constant.

We now consider the probability to transition to a bunch of states in a range $[E_i-\delta, E_i+\delta]$: $$P_{ni}=\int_{E_i-\delta}^{E_i+\delta} dE_n \frac{2\pi}{\hbar}|V_{ni}^2| \delta(E_{ni})\rho(E_n),$$ where $dE_n\rho(E_n)=dN$ is the number of states accessible around $n$. This becomes $$P_{ni}\simeq\frac{2\pi}{\hbar}|V_{ni}|^2\rho(E_n),$$ where $\rho(E_n)$ is a sum over states that simplifies to the derived delta function if only one state is accessible.

\subsection{Harmonic Perturbations}

A large class of problems involve harmonic interactions, not some sudden ones. In this case, we have $$V(t)=Ve^{i\omega t}+V^\dagger e^{-i\omega t},$$ and in general we can do this Fourier component by Fourier component for a general time-dependent perturbation.

In this case, assuming the perturbation again starts at $t=0$, we have after pulling out the interaction picture converters and assuming $V$ is constant $$c_{ni}(t)\approx \frac{-i}{\hbar}\int_0^t dt' \la n|V|i\ra\left[ e^{i(\omega+\omega_{ni})t} + e^{i(-\omega+\omega_{ni})t} \right]\to \frac{-1}{\hbar}\left[\frac{e^{i(\omega+\omega_{ni})t}-1}{\omega+\omega_{ni}}+\frac{e^{i(-\omega+\omega_{ni})t}-1}{-\omega+\omega_{ni}}\right]$$ which gives a probability of the form $$P_{ni}=\frac{2\pi}{\hbar}(\rho(E+E_{ni})+\rho(E-E_{ni})).$$ That is, this contains the stimulated emission and absorption between states $n$ and $i$ differing in energy by $\hbar\omega$.

\subsection{Scattering of Atoms by Light}

We assume the system (atom) has a ground state energy $E_o$ and its ionization energy is defined to be $0$. We ask two questions: if the electron of the atom is in the ground state, what is the probability of exciting it to another bound state $|n\ra$? And what is the probability to ionize the electron?

We begin with the excitation question. We assume the form of the Coulomb Hamiltonian $\Ham_o$, and we shine classical light on the atom.

The Hamiltonian will couple to the EM field: $$\Ham= \frac{1}{2m}(\mom-\frac{e}{c}\vec{A})^2 + eA_o + V_c(r).$$ The vector potential $\vec{A}$ is associated with the light, and it is space-time dependent (not just time-dependent). We write it as a plane wave: $$\vec{A}=\vec{\epsilon}\cdot 2A_o\cos(\omega t-\vec{k}\cdot\vec{x})=\vec{\epsilon}\cdot A_o\left[e^{i\omega t-i\vec{k}\cdot\vec{x}}+e^{-i\omega t+i\vec{k}\cdot\vec{x}}\right],$$ which is harmonic and monochromatic. We note that $\omega=c|\vec{k}|$, where $\vec{k}$ is the wavenumber vector, and $\vec{\epsilon}$ is the transverse polarization. (See diagram drawn in notes). Expanding yields the Hamiltonian $$\Ham = \frac{p^2}{2m}+V_c(r)-\frac{e}{2mc}\left[\vec{p}\cdot\vec{A}+\vec{A}\cdot\vec{p}\right] \frac{e^2}{2mc^2}|\vec{A}|^2+eA_o,$$ where the first two terms are the atom's intrinsic Hamiltonian, the next two are associated with the light, and the final term is 0, since $A_o=0$ for light rays. (?) We note that $$\vec{p}\cdot\vec{A}=\frac{\hbar}{i}\nabla\cdot\vec{A},$$ but since $\vec{A}$ has a curl then it has no divergence. Thus when the product rule is used, the term where the divergence acts on $\vec{A}$ vanishes and leaves another term of $\vec{A}\cdot\vec{p}$. So $$\Ham=\Ham_o-\frac{e}{mc}\vec{A}\cdot\vec{p} +\frac{e^2}{2mc^2}|\vec{A}|^2,$$ where the second term is an actual operator and the final term is just a complex number (since we are assuming that the light is classical). So our time dependent potential interaction term is thus $$V(t)=\frac{-e}{mc}\left[A_oe^{i\omega t-i\vec{k}\cdot\vec{x}}+A_o^* e^{-i\omega t+i\vec{k}\cdot\vec{x}}\right]\vec{\epsilon}\cdot\vec{p}.$$ We recall the general form of the probability of transition is $$P_{ni}\simeq \frac{2\pi}{\hbar}|V_{ni}|^2\delta(E-E_{ni})$$ (for excitation only, not stimulated emission). Now $$|V_{ni}|^2 = \left(\frac{eA_o}{mc}\right)^2 |\la n |e^{-i\vec{k}\cdot\vec{x}}\vec{\epsilon}\cdot\vec{p}|i\ra|^2.$$ The spatial dependence comes out while the time dependence is stuck inside the $\rho(E-E_{ni})\leftrightarrow \delta(E-E_{ni})$ term, as the integral is with respect to time.

\subsection{Cross-Section}
We now note that this question is normally quantified by a reaction cross section, involving the rate of transition: $$\sigma_{in}\equiv\frac{(\#/t)_{sc}}{(\#/(tA))_{inc}}\equiv \frac{(\hbar/\omega)_{sc}}{(E/(tA))_{inc}},$$ where the first definition is just the number scattered (i.e., the rate of transition) over the initial rate incoming/area (flux), and the second is the power scattered over the power/area incoming. It's usually easier to characterize by power, so we multiply the rate by $\hbar/\omega$ for the scattered power. But what is the incoming power/area?

This is a classical wave problem, since the light is classical. The Poynting vector $\vec{S}=\frac{c}{4\pi}(\vec{E}\times\vec{B})$ is the flux of energy of the light (i.e., the power per area). But this is an oriented value, and we only care about the magnitude: $$|\vec{S}|=\frac{c}{4\pi}|\vec{B}(t)|^2 = \frac{c|\vec{k}|^2}{4\pi}\vec{A}^2,$$ since $\vec{B}=\nabla\times\vec{A}=-i\vec{k}\times\vec{A}$ given the plane wave form. Now $$\vec{A}=\vec{\epsilon}\cdot 2A_o\cos(\omega t-\vec{k}\cdot\vec{x})\implies |\vec{A}|^2 = 4A_o^2\cos^2(\omega t-\vec{k}\cdot\vec{x}).$$ We will take the average of $\vec{A}$ over its period, and averaging any sine or cosine function squared over a period just yields 1/2. So $$\la |\vec{A}|^2\ra_T=2A_o^2.$$ So the average power per area is $$|\vec{S}|=\frac{c|\vec{k}|^2}{4\pi}|\vec{A}|^2\overset{"T"}{\to}\frac{cA_o^2}{2\pi}|\vec{k}|^2.$$ So now $$\sigma_{in}=\frac{(\hbar\omega)P_{ni}}{\frac{c|\vec{k}|^2A_o^2}{2\pi}} = \hbar\omega\frac{2\pi}{\hbar} \frac{e^2A_o^2}{m^2c^2}P_{ni}^2\cdot\frac{2\pi}{c|\vec{k}|^2A_o^2}=\frac{4\pi^2}{\omega}\frac{e^2}{m^2c}P_{ni}^2\to \frac{4\pi^2\hbar}{\omega m^2}\alpha P_{ni}^2,$$ where we've inserted the fine structure constant $\alpha=e^2/\hbar c.$ Now we're concerned with $$P_{ni}^2 = |\la n | e^{-i\vec{k}\cdot\vec{x}}\vec{\epsilon}\cdot\vec{p}|i\ra|^2,$$ with $|\vec{k}| = 2\pi/\lambda$. Is $\lambda \gg a$, where $a$ is the size of the atom, then $ka\ll 1$. So if the size is small, we can ignore the modulation term in space (since $\vec{k}\cdot\vec{x}=ka\cos\theta$). We could expand $$e^{-i\vec{k}\cdot\vec{x}}\simeq \Id - i\vec{k}\cdot\vec{x}\simeq \Id,$$ or just note the exponential term is almost zero so it can be approximated as $\Id$. Now $$P_{ni}\simeq \la n |\vec{\epsilon}\cdot\vec{p}|i\ra.$$ Now we note that $\vec{p}$ is tied to position by commutation: $$\left[\Ham_o=\frac{p^2}{2m}+V_c(\vec{x}), \vec{x}\right],$$  where $\vec{x}$ will commute with the potential leaving $[\sim]=-i\hbar \vec{p}/m.$ So $$\vec{p}=\frac{i}{\hbar}m [\Ham_o, \vec{x}].$$ We thus see that $$P_{ni}\simeq \la n |\vec{\epsilon}\cdot\vec{p}|i\ra \to \frac{im}{\hbar}\la n |[\Ham_o, \epsilon\cdot\vec{x}]|i\ra = im\omega_{ni}\la n|\vec{\epsilon}\cdot\vec{x}|i\ra.$$ Here, $\omega_{ni}=\omega$. So we recover a form of the dipole approximation: $$\sigma_{in}=4\pi^2\hbar\omega\alpha|\la n |\vec{\epsilon}\cdot\vec{x}|i\ra|^2.$$

\section{Day 16: 3/23}

 TEST. 
 
 
\section{Day 17: 3/27}
We continue on with developing the excitation cross-section derivation. Class began with the same work, leading up to the final $$\sigma_{ni}=4\pi^2\alpha\hbar\omega |\la n|\vec{\epsilon}\cdot\vec{x}|i\ra|^2\delta_{ni},$$ (note the $\delta_{ni}$ was meant to be in the equation from Day 15 too), and it was noted that this result is consistent if we had started with an interaction Hamiltonian $\Ham_{int}=-\vec{p}\cdot\vec{E}$ as well, instead of the vector potential factor proportional to $\vec{A}\cdot\vec{p}$. All we have to do now is input the Coulomb wave functions and calculate.

\subsection{Sum Rule}

We can sum over all the frequencies of light and the possible final states $|n\ra$ to get an average $\la\sigma_{tot}\ra$: $$\la \sigma_{tot}\ra = \int d\omega \sum_n\sigma_{in}(\omega)=\int d\omega\sum_n (4\pi^2\alpha\hbar\omega)|\la n|\vec{\epsilon}\cdot\vec{x}|i\ra|^2\delta(E_n-E_i-\hbar\omega).$$ We note here that the factor of $\omega$ is taken care of by the delta function, and enforces $\hbar\omega\to E_n-E_i,$ and all the integrals vanish now. Now we reabsorb the factor $E_n-E_i$ back into an expectation value, and use completeness to find $$\la\sigma_{tot}\ra = \frac{4\pi^2\alpha}{\hbar}\sum_n \la i |\vec{\epsilon}\cdot\vec{x}|n\ra \la n|[\Ham_o,\vec{\epsilon}\cdot\vec{x}]|i\ra = \frac{4\pi^2\alpha}{\hbar}\la i |\vec{\epsilon}\cdot\vec{x}[\Ham_o, \vec{\epsilon}\cdot\vec{x}]|i\ra.$$ Since this was an average (sum?) over the frequencies, it has units of $A\cdot\omega=A/t$.



\subsection{Cross-Section for Ionization}

We now consider the reaction $\gamma+H\to H^++e^-,$ or ionization of the atom by an incoming photon. In this instance, we excited from $|i\ra$ to the continuum by $\hbar\omega$. We consider $i=0$, and have $$\psi_0(r)=\frac{1}{\sqrt{\pi}}\frac{e^{-Zr/a}}{(a/Z)^{3/2}}.$$ From now on, we let $a_Z=a/Z$. The final state will be in the continuum, so we assume a plane-wave form $$\psi_n(r)=\frac{e^{i\vec{k}_n\cdot\vec{r}}}{L^{3/2}},$$ in some volume $L^3$. In an infinitesimal volume (normalized by $2\pi$), we have $$dN_{\vec{k}}=\frac{L^3d^3k}{(2\pi)^3}\cdot 2,$$ where the first factor is the phase space volume and the second is because of spin up and down electrons. Integrating over a sphere, we have $$N_{\vec{k}}=\frac{2L^3}{(2\pi)^3}\frac{4\pi}{3}k^3 = \frac{(Lk^3)}{3\pi^2}\implies dN_{\vec{k}}=\frac{L^3k^2}{\pi^2}.$$ Now $$E_k=\frac{\hbar^2k^2}{2m}\implies dE_k = \frac{\hbar^2k}{m},$$ so we have a density of states $$\rho(E_k)=\frac{dN_k}{dE_k}=\frac{L^3km}{\hbar^2\pi^2}.$$ We know that $$\sigma_{in} = \frac{2\pi}{\hbar}\frac{\hbar\omega}{\la |\vec{S}|\ra}|V_{ni}|^2\delta(E_n-E_i-\hbar\omega)$$ in the discrete-to-discrete transition case. In the discrete to continuous case, the infinitesimal form becomes $$d\sigma_{ik}=\frac{2\pi}{\hbar}\frac{\hbar\omega}{\la|\vec{S}|\ra}|V_{ki}|^2\delta(E_n-E_i-\hbar\omega)\cdot\frac{dN_k}{dE_k}\cdot dE_k,$$ and taking this to be over the solid angle: $$\frac{d\sigma_{ik}}{d\Omega_k}=\frac{2\pi}{\hbar}\frac{\hbar\omega}{\la|\vec{S}|\ra} \frac{|V_{ki}|^2}{4\pi}\delta(E_n-E_i-\hbar\omega)\rho(E_k)dE_k.$$ We plug in our values for $\rho(E_k)$ and $dE_k$ as well as the previously calculated value for $\la|\vec{S}|\ra$ to find $$\frac{d\sigma_{ik}}{d\Omega_k}=\left(4\pi^2\alpha\cdot\frac{\hbar}{m^2\omega}\right)\cdot\frac{L^3k^2}{\pi^2}\frac{|V_{ni}|^2}{4\pi}.$$ Now we need only calculate the matrix element $V_{ki}$.

$$V_{ki}=\la k|e^{i\vec{k}_\gamma\cdot\vec{x}} \vec{\epsilon}\cdot\vec{p}|i\ra = \int d\vec{x} \frac{e^{-i\vec{k}_n\cdot\vec{x}}}{L^{3/2}}e^{i\vec{k}_\gamma\cdot\vec{x}}\left(\vec{\epsilon}\cdot\frac{\hbar}{i}\vec{\nabla}\right)\frac{e^{-a_Zr}}{\sqrt{\pi}a_Z^{3/2}},$$ where we inserted the $|x\ra\la x|$ filter next to $\la k |$. We note the integration is over $d\vec{x}$, where as the nabla acts on a function of $r$, so we integrate by parts knowing that the wavefunctions vanish at the boundaries (or infinity). The nabla then acting on the plane-wave continuum state combined with the photon plane-wave modulation brings down a factor of $i(\vec{k}_\gamma-\vec{k}_n)\equiv i\vec{q}$, where $\vec{q}$ is the momentum transfer caused by the photon collision. 

We now have, pulling all the constant factors out, $$V_{ki} = \frac{\hbar\vec{q}\cdot\vec{\epsilon}}{L^{3/2}\sqrt{\pi}a_Z^{3/2}}\int d\vec{x}e^{-i\vec{q}\cdot\vec{x}-r/a_Z}.$$ The integral is just a Fourier transform with respect to the vector $\vec{q}$: $$I=\int d\vec{x}e^{-\vec{q}\cdot\vec{x}-r/a_Z} = 2\pi\cdot\int_0^\infty r^2dr \int_0^\pi d(-\cos\theta)e^{-iqr\cos\theta - r/a_Z}.$$ The integral over $d(-\cos\theta)$ yields $$I=2\pi\cdot\int_0^\infty r^2dr\frac{1}{-iqr}\left[e^{iqr-r/a_Z}-e^{-iqr-r/a_Z}\right]=\frac{2\pi i}{q}\cdot\int_0^\infty r dr \left[e^{-\alpha r}-e^{-\bar{\alpha}r}\right].$$ Noting that $$\int_0^\infty rdr e^{-\alpha r} = \ptl_{-\alpha}\int_0^\infty  dr e^{-\alpha r} = \ptl_{-\alpha}\frac{1}{\alpha}=\frac{1}{\alpha^2},$$ we finally get $$I=\frac{2\pi i}{q}\cdot\frac{2iq}{a_Z(a_Z^{-2}+q^2)} = \frac{-4\pi}{a_Z(a_Z^{-2}+q^2)^2}.$$ Now we substitute the integration into the matrix element: $$V_{ki}= \frac{\hbar\vec{q}\cdot\vec{\epsilon}}{L^{3/2}\sqrt{\pi}a_Z^{3/2}}\cdot I = \frac{\hbar\vec{q}\cdot\vec{\epsilon}}{L^{3/2}\sqrt{\pi}a_Z^{3/2}} \cdot \frac{-4\pi}{a_Z(a_Z^{-2}+q^2)^2}.$$ This finally yields the result \begin{align*} \frac{d\sigma_{ik}}{d\Omega_k} &=\left(4\pi^2\alpha\cdot\frac{\hbar}{m^2\omega}\right)\cdot\frac{L^3k^2}{\pi^2}\frac{|V_{ni}|^2}{4\pi}\\
&= \left(4\pi^2\alpha\cdot\frac{\hbar}{m^2\omega}\right)\cdot\frac{L^3k^2}{\pi^2}\frac{1}{4\pi}\cdot\frac{\hbar^2(\vec{q}\cdot\vec{\epsilon})^2}{\pi L^3 a_Z^3}\cdot\frac{16\pi^2}{a_Z^2(a_Z^{-2}+q^2)^4}\\
&= \frac{16 k^2\hbar^3 \alpha}{m^2\omega}\cdot\frac{1}{a_Z^5(a_Z^{-2}+q^2)^4}.\end{align*} (???) In class derivation was wrong. This was closer but doesn't match Sakurai up to a factor of $2k_n$.




\section{Day 18: 3/29}

\subsection{Ionization Cross-Section Redo}
We shine light $\gamma$ onto an atom and ionize the electron from $|i\ra$ to the continuum $|n\ra$. Fermi's golden rule states that the rate of probability $$w_{if}\simeq \frac{2\pi}{\hbar}|V_{ni}|^2\delta_{ni},$$ where $\delta_{ni}$ is the energy delta function matching the photon energy to the difference in energy between initial and final states. Since the electron is excited into the continuum, there is a density of final states. To preserve this, we make the probability rate infinitesimal and multiply by an infinitesimal number of accessible nearby states (?) $$dw_{ij}= \frac{2\pi}{\hbar}|V_{ni}|^2 \delta_{ni}dN,$$ where the final state is a plane wave (normalized to some volume) and the initial state is the ground Coulomb state. We note that the number of final states is the phase-space volume (normalized to a cube with length $2\pi$) times the space volume (?) $$N_f=\frac{L^3\cdot 4\pi k_f^3}{3(2\pi)^3}\cdot 2,$$ where the factor of 2 comes from the multiple available spins. This is a space-based counting of available plane waves. So $$dN=\frac{L^3k_f^2}{\pi^2}dk_f.$$ Now we note that we have $dw_{if}$ but we are really concerned with the cross section, which again is (in our calculations) the energy scattered ($w_{ij}\cdot\hbar\omega$) divided by the incoming energy flux $\la|\vec{S}|\ra$ of the light. We also recall in the $ka\ll 1$ regime, $$|V_{in}|^2 = \left(\frac{eA_o}{mc}\right)^2 |\la n|e^{i\vec{k}\cdot\vec{x}}\vec{\epsilon}\cdot\vec{p}|i\ra|^2,$$ so that $$\frac{d\sigma_{in}}{dk_n} = 4\pi^2\alpha \frac{\hbar}{m^2\omega} P_{ni}^2 \frac{L^3k_n^2}{\pi^2}\delta_{ni}$$ after everything is plugged back in. $P_{ni}$ ends up evaluating to $$P_{ni}=\frac{8\pi}{(1+q^2a_z^2)^2},$$ which yields a final $$\frac{d\sigma_{in}}{dk_n} = \frac{4\alpha}{\pi}\cdot\frac{\hbar}{m^2\omega}\cdot(a_Z^3k_n^2)\cdot|\vec{\epsilon}\cdot\hbar\vec{q}|^2\cdot\frac{(8\pi)^2}{(1+q^2a_z^2)^4}.$$ We see at high momentum transfer $\vec{q}$ the cross section falls off with the factor of $q^{-6}$, and small cross section grows as $q^2$. 

Dimensional analysis shows this having matching dimensions on both sides, although the dimensions are of volume for some reason...

\subsection{Variational Analysis}

We conclude time-dependent perturbation theory and move on to variational methods. This depends on making a guess regarding the nature of the solution, depending on certain parameters. We calculate the guessed (GROUND) function's energy and then minimize it with respect to the parameters. This is an important method that has resulted in many Nobel prizes: good guessing is an art for complicated situations.

We consider the Helium atom, composed of 2 positive and 2 negative charges. We again consider the protons fixed in place, and have $$\Ham=\Ham_1+\Ham_2-\frac{e^2}{r_{12}},$$ where the final interaction term is what makes this problem not solvable. We have $$\Ham_1 = \frac{p_1^2}{2m}-\frac{e^2}{r_1}-\frac{e^2}{|\vec{r}_1-\vec{d}|}, \ \ \ \Ham_2= \frac{p_2^2}{2m}-\frac{e^2}{r_2}-\frac{e^2}{|\vec{r}_2-\vec{d}|},$$ where each electron's radial vector points to a single hydrogen and the vector $\vec{d}$ is the distance vector between the two hydrogens. We want to find $\Ham\Psi(\vec{r}_1,\vec{r}_2)=E\Psi(\vec{r}_1,\vec{r}_2).$

In the variational approach, we guess the best possible outcome for the ground state solution. We note that each individual electron will see a charge between $+1$ and $+2$, due to the Coulombic screening caused by the other electron. So we guess $$\Psi_Z(\vec{r}_1,\vec{r}_2) = \psi_Z(\vec{r}_1)\psi_Z(\vec{r}_2), \ \ \ Z\in[1,2].$$ If $Z$ is optimal, it minimizes the guessed energy. We form the ratio $$\epsilon(Z)=\frac{\la \Psi_Z|\Ham|\Psi_z\ra}{\la\Psi_Z|\Psi_Z\ra}.$$ Thus $Z$ is fixed by the condition $$\ptl_Z\epsilon = 0.$$ This should be a minimum only, not any other extremum. This is why we can only use this method for ground state calculations, because any other state could be deformed into the ground state energy.

For He, we use a Coulombic wavefunction for each electron with effective charge $Z$: $$\Psi_Z(\vec{r}_1,\vec{r}_2)=\psi_Z(\vec{r}_1)\psi_Z(\vec{r}_2), \ \ \ \psi_Z(\vec{r}_i)=\frac{1}{\sqrt{\pi}a_Z^{3/2}}e^{-r_i/a_z}, a_Z=\frac{a_o}{Z}.$$ We note that these functions are already normalized, so $\la\Psi_Z|\Psi_Z\ra=1$. Thus we have \begin{align*}
\la \Psi_Z|\Ham|\Psi_z\ra &= \la \psi^1_Z\psi^2_Z|\Ham_1+\Ham_2-\frac{e^2}{r_{12}}|\psi_Z^1\psi_Z^2\ra\\
&= 2 \la \psi_Z^1|\Ham_1|\psi_Z^1\ra - \la\psi^1_Z\psi^2_Z|\frac{e^2}{r_{12}}|\psi_Z^1\psi_Z^2\ra,
\end{align*} where we've used the symmetry to simplify the first term (somehow).

Now \begin{align*}
\la \psi|\Ham_1|\psi\ra &= \la \psi | \frac{p^2}{2m}-\frac{e^2}{r_1}-\frac{e^2}{|\vec{r}_1-\vec{d}|}|\psi\ra \\
&= \la \psi|\frac{p^2}{2m}-\frac{2e^2}{r}|\psi\ra\\
&= \frac{-e^2}{2a_o}(-Z^2) + \frac{2}{Z}\la \psi|\frac{-Ze^2}{r}|\psi\ra \\
&= \frac{-e^2}{2a_o}(-Z^2+4Z), 
\end{align*} where the second equality holds from the symmetry of the problem, the third holds from the virial theorem, and the fourth holds from the Coulomb energies.




\section{Day 19: Albany}

\section{Day 20: 4/5}

I made a 15/30 on the test, while the average was a 21. /sigh

\subsection{Test Overview}

Show that any vector operator transforms as $[J_i, V_j]=i\hbar \epsilon_{ijk}V_k$. This depends entirely on knowing that $$D^\dagger(R)V_iD(R)=R_{ij}V_j,$$ or that the components of the vector operator just rotate as in the Cartesian coordinate system. Knowing $D(R)=e^{-i\vec{J}\cdot\vec{\epsilon}/\hbar}$, we can expand to find \begin{align*}
(\Id+iJ_\epsilon/\hbar)V_i(\Id-iJ_\epsilon/\hbar)&=(\Id+G_\epsilon)_{ij}V_j\\
[J_\epsilon, V_i] &= -i\hbar (G_\epsilon)_{ij}V_j\\
[J_m, V_i] &= -i\hbar (G_m)_{ij}V_j, \ \ \ (G_m)_{ij}=\epsilon_{imj}\\
[J_m, V_i] &= i \hbar \epsilon_{mij}V_j.
\end{align*} The next part used this. With $V_o = V_z, V_{\pm}=(V_x\pm iV_y)/\sqrt{2},$ we had $[J_+, V_-]=i\hbar V_o$. So $$\frac{\la \alpha' j j-1|V_-|\alpha jj\ra}{\la \alpha' jj| V_o |\alpha jj\ra} = \frac{i}{\sqrt{2j}},$$ after inputting the commutation relation into the denominator and cancelling. The matrix element on top cancels with what is left over on the bottom.

For problem two I basically did it right besides accidentally forgetting to square a two somewhere. Naturally. Problem 3 was alright. I'm tired.

\subsection{Many Particles}

We note that distinguishable ensembles of particles have wavefunctions with no specific symmetry under permutation, because they're labeled or whatever.

Indistinguishable particles have $N!$ possible permutations with the same energy. For fermions and bosons, $$P_{ij}|\psi_F(123\dots ij \dots N)\ra = -|\psi_F(123\dots ij \dots N)\ra, \ \ \ P_{ij}|\psi_B(123\dots ij \dots N)\ra = |\psi_B(123\dots ij \dots N)\ra.$$ That is, bosonic wavefunctions for many particle systems are symmetric under pair exchange while fermionic ones are antisymmetric.

Zahed notes a good way to get the signs in the antisymmetric one is to use a determinant: $$\psi_{1\to N}(r_1\dots r_n)= \frac{1}{\sqrt{N!}} \left|\begin{matrix}
\phi_1(r_1) & \dots & \phi_1(r_N)\\
\vdots & \dots & \vdots \\
\phi_N(r_1) & \dots & \phi_N(r_N)
\end{matrix}\right|.$$

For example, we consider two spin-1/2 particles, who can combine into a singlet $|00\ra$ state or a triplet state $|11\ra, |1-1\ra, |10\ra$. Since the triplet states have integer spin, they must be bosonic and thus symmetric. The only remaining choice for antisymmetry is now $|00\ra$, which yields the familiar forms.

If other quantum numbers describe the system, then it is possible that the triplet states are accessible and the antisymmetry occurs in the other numbers. We note that these states arose from $\vec{S}=\vec{S}_1+\vec{S}_2 = \vec{0}+\vec{1}$.

For 3 particles, we have \begin{align*}\vec{S}&=\vec{S}_1+\vec{S}_2+\vec{S}_3\\ &= \vec{\frac{1}{2}} + \vec{\frac{1}{2}} + \vec{\frac{1}{2}}\\
&= (\vec{0}+\vec{1})+\vec{\frac{1}{2}} \\ &= \vec{\frac{1}{2}} + \vec{\frac{1}{2}} + \vec{\frac{3}{2}},
\end{align*} where we combine pairwise until we get the final answer.

\subsection{Young Tableaux and Young's Rule}

We note for our given system we have $\boxed{\uparrow}, \boxed{\downarrow}$ or $\boxed{1}, \boxed{2}$. We define box multiplication as $$\boxed{df}\times\boxed{df} = \boxed{df}/\boxed{df-1} \oplus \boxed{df}\boxed{df+1}.$$
?? Look up somewhere coherent I guess.


\section{Day 21: 4/10}

\subsection{Young Tableau}

This is a convenient way to visualize the symmetry of many-particle representations, and identify the structure of the symmetry.

We begin with a $\square$ that can have inside of it an index representing the state. For example, in spin-1/2 there are $2s+1=2$ states, yielding $\boxed{\uparrow},\boxed{\downarrow}$ corresponding to $\boxed{1},\boxed{2}$. For one particle, a single box with a single label is all that is allowed, yielding only two possible states.

For two particles, we define box multiplication as follows: $$\square\times\square = \begin{matrix}
\square \\ \square
\end{matrix} + \begin{matrix}
\square & \square
\end{matrix}.$$ The labeling rules of such a structure are as follows: moving vertically down a column, the label must \textbf{always increase}, while moving horizontally across a row allows for \textbf{same values or increasing}. So, for the spin-1/2 labels 1 and 2, we find that only $$\begin{matrix}
\boxed{1}\\\boxed{2}
\end{matrix}, \begin{matrix}
\boxed{1}\boxed{1}, & & \boxed{1}\boxed{2}, & & \boxed{2}\boxed{2}
\end{matrix}$$ are the only possible states. The Young tableau is a useful way to keep track of the number of symmetries allowed in many particle systems.

The rules are as follows:

\textbf{Stacking.} Box multiplication allows stacking either horizontally to the right or vertically on the bottom, always left-justifying the result. For example, using indices to denote which particle we're keeping track of, a three particle system is represented as $$\square_1\times(\square_2\times\square_3)=\square_1\times\left(\begin{matrix}
\square_2\\\square_3
\end{matrix}+\begin{matrix}
\square_2\square_3
\end{matrix}\right) = \left(\begin{matrix}
\square_1\\\square_2\\\square_3
\end{matrix}+\begin{matrix}
\square_2& \square_1 \\\square_3 & 
\end{matrix}\right) + \left(\begin{matrix}
\square_2 & \square_3\\\square_1 &
\end{matrix}+\begin{matrix}
\square_1\square_2\square_3
\end{matrix}\right)$$


\textbf{Labeling.} The labels depend on the start block, which is always the top left hand block. In, for example a spin $N$ system with $2N+1$ states, labeling downward along a column \textbf{must always yield a strictly increasing sequence} of labels. No repetition or smaller values. Along a row, repetition is allowed but it must be increasing otherwise. If one were to run out of labels going downwards, for example, then that state is not allowed to exist.

\textbf{Counting.} To count the number of total states for a given representation block, we \textbf{insert the number of labels $N$ into the starting block.} We then decrement by units of one going down the column, and increment by units of one going across the row. The numerator will be the product of all of the entries: $$\begin{matrix}
\boxed{N} & \boxed{N+1}&\boxed{N+2}\\
\boxed{N-1} & \boxed{N} & \\
\boxed{N-2} &&
\end{matrix}$$ As an example, the above figure gives a numerator of $N^2(N-1)(N-2)(N+1)(N+2)$. We then form the denominator by \textbf{hook counting}. Here, we start at the top row and insert a right-angled hook for each column, and count the number of boxes we cross. We then repeat for the rows below. This yields a denominator of $1\cdot 3\cdot 5\cdot 1\cdot 3 \cdot 1$. So the number of available states in that given block representation above is $$\# = \frac{N^2(N-1)(N-2)(N+1)(N+2)}{1\cdot3\cdot5\cdot1\cdot3\cdot1}$$ in that 6 particle system.

\textbf{All horizontal labels are symmetric with respect to swapping, and all vertical labels are antisymmetric with respect to pair exchange.}


\subsection{SU(N) Groups}

In a two particle system, we expect $N^2$ possible states given $N$ labels. This is verified by the counting method we defined above.

\subsection{Quark Model}

In the 1960s, accelerators were being advanced and many new particles were being discovered that didn't agree with the proton and neutron fundamental particle picture. So it was postulated that the nuclear components were fermion composites. Given that observed particles were fermionic, they had to have fermion constituents or else no fermion particles could have been observed.

Gellmann and Zweig (independently?) put forth that there were three flavors of fermion components: $u, d, s$ (up, down, and strange). In reality there are six, but these $t,b,c$ (top, bottom, charm) quark particles weren't available to the energy levels at the time. Anyway, for this model to work the 3 flavors must have fractional charge. They defined $$Q=I_3+\frac{Y}{2},$$ where $Q$ is the electric charge of the quark, $I_3$ is its isospin, and $Y$ is its hypercharge. In the $I_3\times Y$ space, these particles form a triangle with vertices $$\{f=(I_3, Y): u=(1/2, 1/3), d = (-1/2, 1/3), s=(0, -2/3)\}.$$ They also postulated that the baryon number of the protons and neutrons was $B=1$, and so each constituent has baryon number $B_u=B_d=B_s=1/3$. Physicists understood well the electric charge conservation and baryon number conservation, but the hypercharge and isospin were new concepts. With these three particles, how many particles can we expect?

This is the same system as our three particle system from before: $$\square_1\times(\square_2\times\square_3)=\square_1\times\left(\begin{matrix}
\square_2\\\square_3
\end{matrix}+\begin{matrix}
\square_2\square_3
\end{matrix}\right) = \left(\begin{matrix}
\square_1\\\square_2\\\square_3
\end{matrix}+\begin{matrix}
\square_2& \square_1 \\\square_3 & 
\end{matrix}\right) + \left(\begin{matrix}
\square_2 & \square_3\\\square_1 &
\end{matrix}+\begin{matrix}
\square_1\square_2\square_3
\end{matrix}\right).$$ Using our hook counting rules with $N=3$, we get $$\# = 1+8+8+10=27$$ new particles that could be formed out of these quarks. These states are totally antisymmetric, have mixed symmetry, or are completely symmetric. We focus on the $10_S$ states (the 10 symmetric states).

\subsection{Color Discovery}

Consider the 10-plet given by our ten possible $\square_1\square_2\square_3$ unique combinations. We let $(123)\leftrightarrow(uds)$, and consider $$\boxed{u}\boxed{u}\boxed{u}.$$ This is a totally symmetric state, but filled with fermions that obey the Pauli exclusion principle. So this should not be allowed. But we consider that each flavor state also has a space state vector, and naively we would assume we can antisymmetrize the space state and be okay: $\Psi(123)=\psi_f(123)\psi_x(123).$ But this turned out to not be satisfactory. Antisymmetrizing the spatial state costs energy, since all ground states are symmetric. We would have to place these up quarks into three different energy states, which would thus allow the states to decay: but into what?

So with this problem, it was postulated that there is a new quantum number, called color, for quarks: $$\Psi(123)=\psi_f(123)\psi_x(123)\psi_c(123),$$ that requires three color charges to be completely antisymmetric. So the ground state 10-plet is described by $$\Psi(123)=\psi_f(123)\psi_x(123)\psi_c(123) = \square\square\square_f\times\square\square\square_x\times\begin{matrix}
\square\\\square\\\square
\end{matrix}_c.$$

This matched observations at the time: \begin{align*}
s=0&: uuu\to \Delta^{++}, \ \ \ uud\to \Delta^+, \ \ \ udd \to \Delta^0, \ \ \ ddd\to \Delta^-\\
s=-1&: uus\to\Sigma^+, \ \ \ uds\to \Sigma^0, \ \ \ dds\to\Sigma^-\\
s=-2&: uss\to \Xi^+, \ \ \ dss\to\Xi^-\\
s=-3&: sss\to\Omega^-
\end{align*}

\subsection{Second Quantization}

We now note that labeling the state with the particle is bad if all particles are the same: $$|\alpha\ra = \sum_p \sigma_p|\phi_{\alpha_1}(1)\phi_{\alpha_2}(2)\dots\phi_{\alpha_N}(N)\ra,$$ because we have to keep track of the symmetries and antisymmetries and as $N$ grows large it becomes very inefficient to do so. Say we want to describe an atom with 100 electrons. Forming the Slater determinant yields the determinant of a matrix with 1000 entries, and the number of states is $100!$, which very quickly becomes not worth keeping track of even on a computer.

Dirac noticed a way to deal with this: we label the states in terms of occupation number. We have N identical particles, each with identical wavefunctions and spectra $\{\epsilon_\alpha,\phi_\alpha(x)\}$. We let $\alpha=1\to\infty$ label the different states, and we want to express the state in terms of occupation number $$|N_1N_2\dots N_\infty\ra$$ subject to $$\sum_{\alpha}N_\alpha=N.$$ We have infinitely many states labeled by their occupation number.

$$|N_1N_2\dots N_\infty\ra = \left(\frac{N_1!N_2!\dots N_\infty!}{N!}\right) \sum_{[p]}\sigma_p |[\beta_1][\beta_2]\dots[\beta_\infty]\ra,$$ where the numerator takes care of the fact that the bosons don't see the permutations.

We take an aside to the 1D harmonic oscillator, with $H=\hbar\omega(a^\dagger a+1/2)$, $a|n\ra = \sqrt{n}|n-1\ra$ and $a^\dagger|n\ra = \sqrt{n+1}|n+1\ra$. We can think of the state $|n\ra$ as either a single state with energy $(n+1/2)\hbar\omega$ or as a large number of particles with energy $\hbar\omega/2$.



\end{document}